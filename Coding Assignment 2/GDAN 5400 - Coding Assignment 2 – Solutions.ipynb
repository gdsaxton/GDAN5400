{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f0d552",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gdsaxton/GDAN%205400/blob/main/Coding%20Assignment%202/GDAN5400%20-%20Coding%20Assignment%202.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583a2bd8",
   "metadata": {},
   "source": [
    "# Coding Assignment #2\n",
    "\n",
    "In this second assignment you will continue working with the room insurance claim dataset you used in Coding Assignment #1. In this assignment, you will:\n",
    "1. Use built-in and custom functions\n",
    "2. Convert data types\n",
    "3. Generate a binary variable\n",
    "4. Drop unneeded columns\n",
    "5. Drop a duplicate observation\n",
    "6. Run frequencies\n",
    "7. Aggregate and group the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50e915",
   "metadata": {},
   "source": [
    "## CASE INTRODUCTION\n",
    "\n",
    "Casey Lee, an insurance claims processor was reviewing claims received from a recent storm before finalizing authorization for roof replacements. She pulled up and reread the U.S. National Weather Service Announcement:\n",
    "\n",
    "&nbsp;&nbsp; TORNADO WARNING  \n",
    "&nbsp;&nbsp; NATIONAL WEATHER SERVICE CHICAGO/ROMEOVILLE   \n",
    "&nbsp;&nbsp;1215 AM CDT THU SEP 12 20XX  \n",
    "\n",
    "&nbsp;&nbsp;THE NATIONAL WEATHER SERVICE IN CHICAGO HAS ISSUED A   \n",
    "&nbsp;&nbsp;*TORNADO WARNING FOR...    \n",
    "&nbsp;&nbsp;CENTRAL DEKALB COUNTY IN NORTH CENTRAL ILLINOIS...    \n",
    "&nbsp;&nbsp;UNTIL 530 PM CDT.  \n",
    "\n",
    "&nbsp;&nbsp;*AT 1218 AM CDT, A SEVERE THUNDERSTORM CAPABLE OF PRODUCING A  \n",
    "&nbsp;&nbsp;TORNADO WAS LOCATED NEAR SYCAMORE,  \n",
    "&nbsp;&nbsp;OR NEAR SHABBONA, MOVING SOUTHWEST AT 2 MPH.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;  HAZARD...TORNADO AND QUARTER-SIZED HAIL.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;  SOURCE...RADAR INDICATED ROTATION.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; IMPACT...FLYING DEBRIS WILL BE DANGEROUS TO THOSE CAUGHT WITHOUT SHELTER.   \n",
    " &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MOBILE HOMES WILL BE DAMAGED OR DESTROYED.  \n",
    "   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   DAMAGE TO ROOFS, WINDOWS, AND VEHICLES WILL OCCUR. TREE DAMAGE IS LIKELY.  \n",
    "\n",
    "&nbsp;&nbsp;*THIS DANGEROUS STORM WILL BE NEAR...  \n",
    "&nbsp;&nbsp;SYCAMORE AROUND 1240 AM CDT.   \n",
    "&nbsp;&nbsp;DEKALB AROUND 600 AM CDT.  \n",
    "&nbsp;&nbsp;COURTLAND AROUND 1140 AM.     \n",
    "\n",
    "&nbsp;&nbsp;PRECAUTIONARY/PREPAREDNESS ACTIONS...   \n",
    "\n",
    "&nbsp;&nbsp;TAKE COVER NOW! MOVE TO A BASEMENT OR AN INTERIOR ROOM  \n",
    "&nbsp;&nbsp;ON THE LOWEST FLOOR OF A STURDY BUILDING.  \n",
    "&nbsp;&nbsp;AVOID WINDOWS. IF YOU ARE OUTDOORS, IN A MOBILE HOME, OR IN A VEHICLE,   \n",
    "&nbsp;&nbsp;MOVE TO THE CLOSEST SUBSTANTIAL SHELTER AND PROTECT YOURSELF FROM FLYING DEBRIS.    \n",
    "\n",
    "Indeed, it appeared to be a bad storm, which could substantiate the large number of claims that she received for new roofs from hail and wind damage. Yet, she felt that something could be off.\n",
    "\n",
    "While Casey could not process the data from multiple companies, she knew that the National Insurance Crime Bureau might be able to help by aggregating data from multiple insurance companies across the area hit by the storm and evaluating the data to look for anomalies. Casey's request landed on your desk. As a new fraud specialist, you have been hired to investigate claims following storm damage to hopefully reduce the payouts made to false claimants. You also knew you had to act fast. You began by pulling the claims data for roofs. You also received a database that showed the actual path of this storm. Your task is to sort through the claims to see if there were any unusual claim patterns from this recent weather event.\n",
    "\n",
    "---\n",
    "Case introduction and dataset comes from: Cheng, C., & Lee, C.-C. (2023). A Case Study Using Data Analytics to Detect Hail Damage Insurance Claim Fraud. *Journal of Forensic Accounting Research, 8,* 287–306."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59bb820",
   "metadata": {},
   "source": [
    "# Load and Prepare the Dataset\n",
    "We will first get set up to run the assignment, using code from Coding Assignment #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5bc0e",
   "metadata": {},
   "source": [
    "### Load the Dataset and show first two rows:\n",
    "  - Load the roof insurance claim dataset (provided in `.xlsx` format) into a Pandas DataFrame named `df`\n",
    "  - Show the first two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# NOTE: replace `https://github.com/` with `https://raw.githubusercontent.com`\n",
    "# https://github.com/gdsaxton/GDAN5400/blob/main/Coding%20Assignment%201/final_insurance_fraud.xlsx\n",
    "url = 'https://raw.githubusercontent.com/gdsaxton/GDAN5400/main/Coding%20Assignment%201/final_insurance_fraud.xlsx'\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open('final_insurance_fraud.xlsx', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('final_insurance_fraud.xlsx', engine='openpyxl')\n",
    "\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba7406",
   "metadata": {},
   "source": [
    "### Apply the data cleaning operations from Coding Assignment #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df = df[df['Policy Number'].notnull()]\n",
    "df['Estimated cost to repair'] = df['Estimated cost to repair'].fillna(0)\n",
    "df['Estimated cost to replace'] = df['Estimated cost to replace'].fillna(0)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce65c6",
   "metadata": {},
   "source": [
    "### Strip any whitespace from column names to avoid issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388ec1d",
   "metadata": {},
   "source": [
    "### **Identify Duplicate Claims:**\n",
    "- Use PANDAS to identify whether there are any duplicate claims in your dataset based on ``House/Apartment Number``,\t``Street Address``, ``City``, and ``Zip Code``.   \n",
    "- This is from Coding Assignment #1 – in the assignment you will be dropping one of these duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(subset=['House/Apartment Number', 'Street Address', 'City', 'Zip Code'], keep=False)]\n",
    "print(f\"Number of duplicate claims: {len(duplicates)}\") #Optional step\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ed435",
   "metadata": {},
   "source": [
    "# **Instructions: Steps to Complete**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e362e",
   "metadata": {},
   "source": [
    "### Task 1: Write and Apply Functions\n",
    "- Create a variable `avg_repair_cost` that calculates the average `Estimated cost to repair` \n",
    "  - *hints*: 1) this is not a variable added to the dataset – it should return a single number; 2) use a `built-in` function for this task\n",
    "- Write a custom function to categorize roof age as 'Old' if `Age of roof` is greater than 15 and 'New' otherwise; apply the function to the dataset and create a new variable in `df` called `roof_age_category`\n",
    "  - After you have created the new variable, show `df` with first 10 rows of only the `Age of roof` and `roof_age_category` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d59c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_repair_cost = df['Estimated cost to repair'].mean()\n",
    "print(\"Average Repair Cost:\", avg_repair_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ab40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roof_age_category(age):\n",
    "    return 'Old' if age > 15 else 'New'\n",
    "df['roof_age_category'] = df['Age of roof'].apply(roof_age_category)\n",
    "print(df['roof_age_category'].value_counts(), '\\n')\n",
    "df[['Age of roof', 'roof_age_category']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b1ed9",
   "metadata": {},
   "source": [
    "### Task 2: Convert Data Type\n",
    "- Convert `Zip Code` to `string` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip Code'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip Code'] = df['Zip Code'].astype(str)\n",
    "df[['Zip Code']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fec89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip Code'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ff236",
   "metadata": {},
   "source": [
    "### Task 3: Create Binary Variable\n",
    "- Create a new variable in `df` that flags claims for high rainfall based on whether `Rainfall` is greater than 1.5\n",
    "  - Call the new variable `high_rainfall` and assign values of 1 for rainfall > 1.5, otherwise 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 1: lambda function\n",
    "df['high_rainfall'] = df['Rainfall'].apply(lambda x: 1 if x > 1.5 else 0)\n",
    "df[['Rainfall', 'high_rainfall']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 2: Custom function \n",
    "def classify_rainfall(rainfall, threshold=1.5):\n",
    "    return 1 if rainfall > threshold else 0\n",
    "\n",
    "# Apply the custom function\n",
    "df['high_rainfall'] = df['Rainfall'].apply(classify_rainfall)\n",
    "df[['Rainfall', 'high_rainfall']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 3: Using a Boolean Condition Directly\n",
    "df['high_rainfall'] = (df['Rainfall'] > 1.5).astype(int)\n",
    "df[['Rainfall', 'high_rainfall']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 4: Using `np.where()` from NumPy\n",
    "import numpy as np\n",
    "df['high_rainfall'] = np.where(df['Rainfall'] > 1.5, 1, 0)\n",
    "df[['Rainfall', 'high_rainfall']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dcf8f",
   "metadata": {},
   "source": [
    "### Task 4: Drop Unnecessary Columns\n",
    "- Drop the following columns from the dataframe: `['Latitude', 'Longitude', 'Telephon number']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007be3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Latitude', 'Longitude', 'Telephon number']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60378fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Latitude', 'Longitude', 'Telephon number']\n",
    "df = df.drop(columns=columns_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d709e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Latitude', 'Longitude', 'Telephon number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ea9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7cd5f",
   "metadata": {},
   "source": [
    "### Task 5: Drop Duplicate Claim\n",
    "Delete one of the duplicate observations from the dataset identified in Coding Assignment #1 (see `duplicates` above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df = df.drop_duplicates(subset=['House/Apartment Number', 'Street Address', 'City', 'Zip Code'], keep='first')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e01f0",
   "metadata": {},
   "source": [
    "<br>[Optional:] We can now re-run the duplicates check and see whether any remain in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(subset=['House/Apartment Number', 'Street Address', 'City', 'Zip Code'], keep=False)]\n",
    "print(f\"Number of duplicate claims: {len(duplicates)}\") #Optional step\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469068c1",
   "metadata": {},
   "source": [
    "### Task 6: Show the Frequencies for `Adjuster` \n",
    "In this dataset, where each row is a different claim, the frequencies will tell us the **_number of claims_** handled by each Adjuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec94b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate claims by Adjuster and Roofing Company\n",
    "adjuster_counts = df['Adjuster'].value_counts()\n",
    "print(type(adjuster_counts))\n",
    "adjuster_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f31392",
   "metadata": {},
   "source": [
    "### Task 7: Aggregate Data to Get Averages by `Roofing Company`\n",
    "- Use `groupby()` to create a new dataframe called `average_by_roofer` that contains the average values of `Estimated cost to repair` and `Estimated cost to replace` for each `Roofing Company`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b60c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_by_roofer = df.groupby('Roofing Company')[['Estimated cost to repair', \n",
    "                                                   'Estimated cost to replace']].mean().reset_index()\n",
    "average_by_roofer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e408920",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Deliverables**\n",
    "1. Submit the link to you Google Colab notebook in the assignment area in Canvas.\n",
    "2. Include comments in your code to explain each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3783423",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "- Submit your completed Colab notebook with all code cells executed.\n",
    "- Ensure your notebook includes helpful explanations (as Markdown cells) for each step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
