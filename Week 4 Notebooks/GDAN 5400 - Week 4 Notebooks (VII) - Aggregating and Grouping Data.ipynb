{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c907206",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gdsaxton/GDAN5400/blob/main/Week%204%20Notebooks/GDAN%205400%20-%20Week%204%20Notebooks%20%28VII%29%20-%20Aggregating%20and%20Grouping%20Data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58dcaba",
   "metadata": {},
   "source": [
    "This notebook provides recipes for aggregating and grouping PANDAS dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9da7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import datetime\n",
    "print (\"Current date and time : \", datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af03858",
   "metadata": {},
   "source": [
    "# Load Packages and Set Working Directory\n",
    "Import several necessary Python packages. We will be using the <a href=\"http://pandas.pydata.org/\">Python Data Analysis Library,</a> or <i>PANDAS</i>, extensively for our data manipulations in this and future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab477ac",
   "metadata": {},
   "source": [
    "<br>\n",
    "PANDAS allows you to set various options for, among other things, inspecting the data. I like to be able to see all of the columns. Therefore, I typically include this line at the top of all my notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://pandas.pydata.org/pandas-docs/stable/options.html\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', 250)\n",
    "pd.set_option('display.max_info_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b452531",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# NOTE: replace `https://github.com/` with `https://raw.githubusercontent.com`\n",
    "# https://github.com/gdsaxton/GDAN5400/blob/main/Coding%20Assignment%201/final_insurance_fraud.xlsx\n",
    "url = 'https://raw.githubusercontent.com/gdsaxton/GDAN5400/main/Coding%20Assignment%201/final_insurance_fraud.xlsx'\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open('final_insurance_fraud.xlsx', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('final_insurance_fraud.xlsx', engine='openpyxl')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db5ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY DATA CLEANING OPERATIONS FROM CODING ASSIGNMENT 1\n",
    "df = df[df['Policy Number'].notnull()]\n",
    "df['Estimated cost to repair'] = df['Estimated cost to repair'].fillna(0)\n",
    "df['Estimated cost to replace'] = df['Estimated cost to replace'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any whitespace from column names to avoid issues\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce74df",
   "metadata": {},
   "source": [
    "# Aggregating and Grouping Data in PANDAS Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb8013",
   "metadata": {},
   "source": [
    "**[ChatGPT prompt]** `How can I aggregate data in PANDAS?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f58bea",
   "metadata": {},
   "source": [
    "# Understanding `groupby()` in PANDAS: A Brief Tutorial\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "In data analysis, the process of **grouping** data and performing **aggregations** is a powerful way to summarize and extract insights. Other terms commonly used for \"grouping\" and \"aggregation\" include:\n",
    "- **Grouping:** Categorizing, clustering, or segmenting data.\n",
    "- **Aggregation:** Summarizing, condensing, or consolidating data.\n",
    "- **Collapse:** Some statistical tools prefer this term.\n",
    "\n",
    "After grouping, you can apply aggregate functions like **count**, **mean**, **sum**, etc., to summarize or analyze data within each group.\n",
    "\n",
    "In pandas, the `groupby()` method is the most effective tool for performing grouping and aggregation tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## **What is `groupby()`?**\n",
    "The `groupby` function in Pandas is a powerful tool for grouping data based on the values of one or more columns.\n",
    " \n",
    "Specifically, `groupby` allows you to implement the `split-apply-combine` technique that is common in data analytics:\n",
    "1. **Split** the data into groups based on one or more columns.\n",
    "2. **Apply** aggregation or transformation functions to each group.\n",
    "3. **Combine** the results into a new DataFrame or Series.\n",
    "\n",
    "Think of it as answering the question: \"What is the sum, mean, or count for each group in my dataset?\"\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **How Does `groupby()` Work?**\n",
    "\n",
    "The operation can be broken into three steps:\n",
    "1. **Split:** Divide the dataset into groups (subsets) based on the unique values of a key column or multiple columns. These are the 'grouping' column(s)\n",
    "2. **Apply:** Apply an aggregation, transformation, or filtering function (e.g., calculate the sum or mean)\n",
    "3. **Combine:** Combine the results back into a new DataFrame or Series.\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Use `groupby`?**\n",
    "- To **summarize** large datasets by specific categories.\n",
    "- To **compare** metrics (e.g., averages, counts) across groups.\n",
    "- To **identify patterns** or outliers within grouped data.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Common Aggregation Functions\n",
    "- `sum()`: Total of the group.\n",
    "- `mean()`: Average of the group.\n",
    "- `count()`: Number of items in the group.\n",
    "- `min()` / `max()`: Minimum or maximum value in the group.\n",
    "- `median()`: Median value in the group.\n",
    "- `std()` / `var()`: Standard deviation or variance of the group.\n",
    "\n",
    "---\n",
    "\n",
    "## **Basic Syntax**\n",
    "\n",
    "```python\n",
    "df.groupby(by='Column_Name')['Another_Column'].agg('aggregation_function')\n",
    "```\n",
    "\n",
    "`by`: Specifies the column(s) to group by.  \n",
    "`agg`: Specifies the aggregation function (e.g., sum, mean, count).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Examples\n",
    "Let's assume your dataframe looks like this:\n",
    "\n",
    "```python\n",
    "data = {\n",
    "\n",
    "    'Client_ID': range(1, 21),\n",
    "\n",
    "    'Industry': ['Retail', 'Manufacturing', 'Tech', 'Finance'] * 5,\n",
    "\n",
    "    'Transaction_Amount': [1500, 2000, 3500, 4000, 4500, 800, 1200, 3000, 700, 2200,\n",
    "\n",
    "                           1800, 2500, 4000, 3700, 3200, 500, 2100, 2900, 3600, 3300],\n",
    "\n",
    "    'Invoice_Status': ['Paid', 'Unpaid', 'Paid', 'Unpaid', 'Paid'] * 4,\n",
    "\n",
    "    'Payment_Delay_Days': [0, 15, 0, 30, 0, 45, 60, 0, 10, 0, 20, 0, 5, 25, 0, 35, 50, 0, 40, 0],\n",
    "\n",
    "    'Zip_Code': [10001, 10002, 10003, 10004, 10005] * 4,\n",
    "\n",
    "    'Region': ['North', 'East', 'West', 'South', 'Central'] * 4,\n",
    "\n",
    "    'Currency': ['USD'] * 20,\n",
    "\n",
    "    'Transaction_Date': pd.date_range(start='2023-01-01', periods=20),\n",
    "\n",
    "    'Tax_Percentage': [5, 8, 10, 7, 6, 4, 5, 9, 6, 7, 5, 10, 8, 7, 6, 9, 4, 7, 5, 6]\n",
    "\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "| Client_ID | Industry       | Transaction_Amount | Invoice_Status | Payment_Delay_Days | Zip_Code | Region   | Currency | Transaction_Date      | Tax_Percentage |\n",
    "|-----------|----------------|--------------------|----------------|--------------------|----------|----------|----------|-----------------------|----------------|\n",
    "| 1         | Retail         | 1500               | Paid           | 0                  | 10001    | North    | USD      | 2023-01-01            | 5              |\n",
    "| 2         | Manufacturing  | 2000               | Unpaid         | 15                 | 10002    | East     | USD      | 2023-01-02            | 8              |\n",
    "| 3         | Tech           | 3500               | Paid           | 0                  | 10003    | West     | USD      | 2023-01-03            | 10             |\n",
    "| 4         | Finance        | 4000               | Unpaid         | 30                 | 10004    | South    | USD      | 2023-01-04            | 7              |\n",
    "| 5         | Retail         | 4500               | Paid           | 0                  | 10005    | Central  | USD      | 2023-01-05            | 6              |\n",
    "| 6         | Manufacturing  | 800                | Unpaid         | 45                 | 10001    | North    | USD      | 2023-01-06            | 4              |\n",
    "| 7         | Tech           | 1200               | Paid           | 60                 | 10002    | East     | USD      | 2023-01-07            | 5              |\n",
    "| 8         | Finance        | 3000               | Unpaid         | 0                  | 10003    | West     | USD      | 2023-01-08            | 9              |\n",
    "| 9         | Retail         | 700                | Paid           | 10                 | 10004    | South    | USD      | 2023-01-09            | 6              |\n",
    "| 10        | Manufacturing  | 2200               | Unpaid         | 0                  | 10005    | Central  | USD      | 2023-01-10            | 7              |\n",
    "| 11        | Tech           | 1800               | Paid           | 20                 | 10001    | North    | USD      | 2023-01-11            | 5              |\n",
    "| 12        | Finance        | 2500               | Unpaid         | 0                  | 10002    | East     | USD      | 2023-01-12            | 10             |\n",
    "| 13        | Retail         | 4000               | Paid           | 5                  | 10003    | West     | USD      | 2023-01-13            | 8              |\n",
    "| 14        | Manufacturing  | 3700               | Unpaid         | 25                 | 10004    | South    | USD      | 2023-01-14            | 7              |\n",
    "| 15        | Tech           | 3200               | Paid           | 0                  | 10005    | Central  | USD      | 2023-01-15            | 6              |\n",
    "| 16        | Finance        | 500                | Unpaid         | 35                 | 10001    | North    | USD      | 2023-01-16            | 9              |\n",
    "| 17        | Retail         | 2100               | Paid           | 50                 | 10002    | East     | USD      | 2023-01-17            | 4              |\n",
    "| 18        | Manufacturing  | 2900               | Unpaid         | 0                  | 10003    | West     | USD      | 2023-01-18            | 7              |\n",
    "| 19        | Tech           | 3600               | Paid           | 40                 | 10004    | South    | USD      | 2023-01-19            | 5              |\n",
    "| 20        | Finance        | 3300               | Unpaid         | 0                  | 10005    | Central  | USD      | 2023-01-20            | 6              |\n",
    "\n",
    "\n",
    "<br>Here are 7 examples of how you can use `groupby()` on the above dataframe. Feel free to copy-and-paste this code into code cells and run the data. Note that this would overwrite `df` above, so if you wanted to return to our hail damage dataset you'd have to re-read in that dataset.\n",
    "\n",
    "1. **Group by a Single Column**  \n",
    "Group the data by the Industry column and calculate the total Transaction_Amount for each group.\n",
    "\n",
    "```python\n",
    "industry_totals = df.groupby('Industry')['Transaction_Amount'].sum()\n",
    "industry_totals\n",
    "```\n",
    "\n",
    "2. **Group by Multiple Columns**  \n",
    "Group by Industry and Region and calculate the total Transaction_Amount.\n",
    "\n",
    "```python\n",
    "industry_region_totals = df.groupby(['Industry', 'Region'])['Transaction_Amount'].sum()\n",
    "industry_region_totals\n",
    "```\n",
    "\n",
    "3. **Using Multiple Aggregation Functions**  \n",
    "You can calculate multiple statistics using agg().\n",
    "```python\n",
    "industry_stats = df.groupby('Industry')['Transaction_Amount'].agg(['sum', 'mean', 'count'])\n",
    "industry_stats\n",
    "```\n",
    "\n",
    "4. **Custom Aggregations with a Function**  \n",
    "You can use a custom function in the aggregation.\n",
    "\n",
    "```python\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "industry_range = df.groupby('Industry')['Transaction_Amount'].agg(range_func)\n",
    "industry_range\n",
    "```\n",
    "\n",
    "5. **Grouping with Multiple Aggregation Functions for Different Columns**  \n",
    "You can apply multiple aggregation functions to different columns.\n",
    "```python\n",
    "grouped = df.groupby('Industry').agg({\n",
    "    'Transaction_Amount': ['sum', 'mean'],\n",
    "    'Payment_Delay_Days': ['max', 'min']})\n",
    "grouped\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Common Aggregation Functions**  \n",
    "- `sum()`: Total of the group.\n",
    "- `mean()`: Average of the group.\n",
    "- `count()`: Number of items in the group.\n",
    "- `min()` / `max()`: Minimum or maximum value in the group.\n",
    "- `median()`: Median value in the group.\n",
    "- `std()` / `var()`: Standard deviation or variance of the group.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "The `groupby()` method in pandas is a versatile and essential tool for summarizing and analyzing data. It allows you to:\n",
    "\n",
    "- Perform grouped calculations efficiently.\n",
    "- Gain insights into patterns within your data.\n",
    "- Simplify complex data manipulation tasks.\n",
    "- Practice with the examples above and experiment with your dataset to understand how groupby() can solve real-world problems.\n",
    "\n",
    "---\n",
    "\n",
    "### Advanced Tips\n",
    "Reset the Index – By default, the result of `groupby()` has a grouped index. Reset it with:\n",
    "```python\n",
    "df.groupby('Industry')['Transaction_Amount'].sum().reset_index()\n",
    "```\n",
    "\n",
    "--- \n",
    "\n",
    "### Additional Note: Outputting a `series` vs. a `dataframe` \n",
    "\n",
    "A **series** is a one-dimensional labeled array that can hold any data type (e.g., integers, floats, strings). It has an index, making it similar to a column in a DataFrame or a dictionary.\n",
    "\n",
    "A **dataFrame** is a two-dimensional labeled data structure with columns of potentially different data types. It can be thought of as a collection of Series sharing the same index.\n",
    "\n",
    "In a `groupby` command, you can designate which type of output you want:\n",
    "- To output a **Series**: Use single brackets (`[]`) with the column name after `groupby`.  \n",
    "  Example: `df.groupby(['Adjuster', 'Type of roof'])['Estimated cost to repair'].sum()`\n",
    "\n",
    "- To output a **DataFrame**: Use double brackets (`[[]]`) with the column name after `groupby`.  \n",
    "  Example: `df.groupby(['Adjuster', 'Type of roof'])[['Estimated cost to repair']].sum()`\n",
    "\n",
    "\n",
    "#### Reasons to Use a **Series**\n",
    "1. **Simpler Structure**:\n",
    "   - If you only need the aggregated data itself without worrying about column names or additional metadata, a Series is more lightweight and simpler to work with.\n",
    "   - A Series has a single name and multi-index levels for the group keys.  \n",
    "\n",
    "2. **Ease of Access**:\n",
    "   - When accessing individual groups or values, the simpler structure of a Series can make operations more direct.\n",
    "\n",
    "3. **Performance**:\n",
    "   - Series operations are slightly faster because there's no overhead of additional column handling.\n",
    "   - Useful when the result is a single column and performance is critical.\n",
    "\n",
    "4. **Simpler Aggregations**:\n",
    "   - If you're applying further computations (e.g., plotting or mathematical operations), the Series structure may be easier to work with directly.\n",
    "   - Example:\n",
    "     ```python\n",
    "     series_result.sum()  # Total of all grouped sums\n",
    "     ```\n",
    "---\n",
    "\n",
    "#### Reasons to Use a **DataFrame**\n",
    "1. **Column Consistency**:\n",
    "   - If you're performing aggregations across multiple columns, a DataFrame is necessary.\n",
    "   - Even with a single column, the DataFrame maintains the same structure, which can make subsequent operations easier to align.\n",
    "\n",
    "2. **Expandability**:\n",
    "   - If you plan to add additional computed columns or join with another DataFrame, having a DataFrame structure is essential.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df_result['Additional Metric'] = df_result['Estimated cost to repair'] / 1000\n",
    "     ```\n",
    "\n",
    "3. **Explicit Column Naming**:\n",
    "   - A DataFrame retains column names, which can make the output more descriptive and self-explanatory.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df_result.columns  # Shows ['Estimated cost to repair']\n",
    "     ```\n",
    "\n",
    "4. **Visualization and Formatting**:\n",
    "   - When creating tables or visualizing data (e.g., with Matplotlib, Seaborn, or Pandas' `.plot()`), DataFrames are generally more flexible and straightforward.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df_result.plot(kind='bar')\n",
    "     ```\n",
    "\n",
    "5. **Interoperability with Pandas Methods**:\n",
    "   - DataFrames provide compatibility with a broader set of Pandas functions that might expect DataFrame input, even for single-column data.\n",
    "   - Example:\n",
    "     ```python\n",
    "     df_result.to_csv('output.csv')\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Differences in Practice\n",
    "- If you're working with **single-column grouped aggregations** that are used for further computation or lightweight operations → **Series** is likely sufficient.\n",
    "- If you need a structure that's consistent, descriptive, and can handle additional data or columns → **DataFrame** is the better choice.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d03ee0",
   "metadata": {},
   "source": [
    "# Examples Using our Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468b159",
   "metadata": {},
   "source": [
    "### 1. Group by a Single Column\n",
    "Calculate the average `Estimated cost to repair` grouped by `Adjuster`. Output a *series*.\n",
    "\n",
    "- To output a **Series**: Use single brackets (`[]`) with the column name after `groupby`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_repair_cost = df.groupby('Adjuster')['Estimated cost to repair'].mean()\n",
    "print(type(avg_repair_cost))\n",
    "avg_repair_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2aba7d",
   "metadata": {},
   "source": [
    "<br>Do the same as above but this time output a *dataframe*. \n",
    "- To output a **DataFrame**: Use double brackets (`[[]]`) with the column name after `groupby`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_repair_cost = df.groupby('Adjuster')[['Estimated cost to repair']].mean()\n",
    "print(type(avg_repair_cost))\n",
    "avg_repair_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a7b3e",
   "metadata": {},
   "source": [
    "<br>My personal preference is to almost always output a dataframe. So, the remaining example will all use the double-bracket syntax in order to produce a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_repair_cost = df.groupby('Adjuster')[['Estimated cost to repair']].sum()\n",
    "total_repair_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948e7f0",
   "metadata": {},
   "source": [
    "<br>Now I will demonstrate some of other aggregation functions that can be applied when running a `groupby` command. Note that in these examples I am creating a dataframe but not assigning a *name* to it. This means that the output is not saved into working memory. If I wanted to retain access to the output, I could modify the following line to the following:\n",
    "\n",
    "```python\n",
    "min_adjuster_cost = df.groupby('Adjuster')[['Estimated cost to repair']].min()\n",
    "```\n",
    "\n",
    "With this modification I would be able to access the `min_adjuster_cost` dataframe at any time during the current session.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a8424a",
   "metadata": {},
   "source": [
    "<br>Using `min()` to get the maximum value for each adjuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Adjuster')[['Estimated cost to repair']].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d592e4",
   "metadata": {},
   "source": [
    "<br>Using `max()` to get the maximum value for each adjuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e99345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Adjuster')[['Estimated cost to repair']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492edeb8",
   "metadata": {},
   "source": [
    "<br>Using `median()` to get the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe241ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Adjuster')[['Estimated cost to repair']].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c197f9",
   "metadata": {},
   "source": [
    "<br>Using `std()` to get the standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Adjuster')[['Estimated cost to repair']].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc551a5",
   "metadata": {},
   "source": [
    "<br>Using `count` in order to get the frequencies for each adjuster. Note the similarities to the output from `value_counts()` in the prior notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669acbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Adjuster')[['Estimated cost to repair']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa7799",
   "metadata": {},
   "source": [
    "<br>Now I will re-run the above line to show what `reset_index()` does. I prefer using it in order for cleaner output, but it is not necessary to do in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Adjuster')[['Estimated cost to repair']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802de2d7",
   "metadata": {},
   "source": [
    "### 2. Group by Multiple Columns\n",
    "Calculate the total `Estimated cost to repair` grouped by `Adjuster` and number of `Stories` in the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_repair_by_type = df.groupby(['Adjuster', 'Stories'])[['Estimated cost to repair']].sum()\n",
    "print(type(total_repair_by_type))\n",
    "total_repair_by_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ca231",
   "metadata": {},
   "source": [
    "### 3. Using Multiple Aggregation Functions\n",
    "Calculate the total, average, and count of `Estimated cost to replace` grouped by `Adjuster`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjuster_stats = df.groupby('Adjuster')[['Estimated cost to replace']].agg(['sum', 'mean', 'count'])\n",
    "adjuster_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd241e",
   "metadata": {},
   "source": [
    "### 4. Custom Aggregations with a Function\n",
    "Create a custom function to calculate the range (max - min) of `Rainfall` for each `Roofing Company`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b156386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_func(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "rainfall_range = df.groupby('Adjuster')[['Rainfall']].agg(range_func)\n",
    "rainfall_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96511fa",
   "metadata": {},
   "source": [
    "### 5. Grouping with Multiple Aggregation Functions for Different Columns\n",
    "Calculate the sum and mean of Estimated cost to repair and the max and min of `Rainfall` grouped by `Adjuster`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Adjuster').agg({\n",
    "    'Estimated cost to repair': ['sum', 'mean'],\n",
    "    'Rainfall': ['max', 'min']})\n",
    "grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
