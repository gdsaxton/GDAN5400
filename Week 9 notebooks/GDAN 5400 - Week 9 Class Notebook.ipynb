{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\"https://colab.research.google.com/github/gdsaxton/GDAN5400/blob/main/Week%209%20Notebooks/GDAN%205400%20-%20Week%209%20Class%20Notebook.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" /></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhVl74Q9kMuG"
   },
   "source": [
    "# Kaggle Competition: Housing Prices – Advanced Regression Techniques\n",
    "\n",
    "In today's class, as well as coding assignment #5 and the final project, we will be using the [Housing Prices](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) competition on Kaggle\n",
    "\n",
    "### Competition Description\n",
    "\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "In this fifth assignment, we are switching to another competition on *Kaggle*, an online platform for data science and machine learning that provides datasets, competitions, collaborative notebooks, and learning resources.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "#### Goal\n",
    "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. \n",
    "\n",
    "#### Metric\n",
    "Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n",
    "\n",
    "---\n",
    "\n",
    "These exercises will help strengthen your ability to explore, preprocess, and model real-world datasets using machine learning. You will gain hands-on experience with data cleaning, feature engineering, and predictive modeling, all while working with a classic dataset in a competitive Kaggle environment.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Data Dictionary\n",
    "\n",
    "As a reference, here is a data dictionary describing the variables you will find in the dataset:\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "| **Data Dictionary** |                   |\n",
    "|---------------------|----------------|\n",
    "| **Feature**         | **Description** |\n",
    "| SalePrice      | Property's sale price in dollars (target variable) |\n",
    "| MSSubClass     | Building class |\n",
    "| MSZoning       | General zoning classification |\n",
    "| LotFrontage    | Linear feet of street connected to property |\n",
    "| LotArea        | Lot size in square feet |\n",
    "| Street         | Type of road access |\n",
    "| Alley          | Type of alley access |\n",
    "| LotShape       | General shape of property |\n",
    "| LandContour    | Flatness of the property |\n",
    "| Utilities      | Type of utilities available |\n",
    "| LotConfig      | Lot configuration |\n",
    "| LandSlope      | Slope of property |\n",
    "| Neighborhood   | Physical locations within Ames city limits |\n",
    "| Condition1     | Proximity to main road or railroad |\n",
    "| Condition2     | Proximity to main road or railroad (if a second is present) |\n",
    "| BldgType       | Type of dwelling |\n",
    "| HouseStyle     | Style of dwelling |\n",
    "| OverallQual    | Overall material and finish quality |\n",
    "| OverallCond    | Overall condition rating |\n",
    "| YearBuilt      | Original construction date |\n",
    "| YearRemodAdd   | Remodel date |\n",
    "| RoofStyle      | Type of roof |\n",
    "| RoofMatl       | Roof material |\n",
    "| Exterior1st    | Exterior covering on house |\n",
    "| Exterior2nd    | Exterior covering on house (if more than one material) |\n",
    "| MasVnrType     | Masonry veneer type |\n",
    "| MasVnrArea     | Masonry veneer area in square feet |\n",
    "| ExterQual      | Exterior material quality |\n",
    "| ExterCond      | Present condition of exterior material |\n",
    "| Foundation     | Type of foundation |\n",
    "| BsmtQual       | Height of the basement |\n",
    "| BsmtCond       | General condition of the basement |\n",
    "| BsmtExposure   | Walkout or garden level basement walls |\n",
    "| BsmtFinType1   | Quality of basement finished area |\n",
    "| BsmtFinSF1     | Type 1 finished square feet |\n",
    "| BsmtFinType2   | Quality of second finished area (if present) |\n",
    "| BsmtFinSF2     | Type 2 finished square feet |\n",
    "| BsmtUnfSF      | Unfinished square feet of basement area |\n",
    "| TotalBsmtSF    | Total square feet of basement area |\n",
    "| Heating        | Type of heating |\n",
    "| HeatingQC      | Heating quality and condition |\n",
    "| CentralAir     | Central air conditioning (Yes/No) |\n",
    "| Electrical     | Electrical system type |\n",
    "| 1stFlrSF       | First floor square feet |\n",
    "| 2ndFlrSF       | Second floor square feet |\n",
    "| LowQualFinSF   | Low quality finished square feet (all floors) |\n",
    "| GrLivArea      | Above grade (ground) living area square feet |\n",
    "| BsmtFullBath   | Basement full bathrooms |\n",
    "| BsmtHalfBath   | Basement half bathrooms |\n",
    "| FullBath       | Full bathrooms above grade |\n",
    "| HalfBath       | Half bathrooms above grade |\n",
    "| Bedroom        | Number of bedrooms above basement level |\n",
    "| Kitchen        | Number of kitchens |\n",
    "| KitchenQual    | Kitchen quality |\n",
    "| TotRmsAbvGrd   | Total rooms above grade (excludes bathrooms) |\n",
    "| Functional     | Home functionality rating |\n",
    "| Fireplaces     | Number of fireplaces |\n",
    "| FireplaceQu    | Fireplace quality |\n",
    "| GarageType     | Garage location |\n",
    "| GarageYrBlt    | Year garage was built |\n",
    "| GarageFinish   | Interior finish of the garage |\n",
    "| GarageCars     | Garage size in car capacity |\n",
    "| GarageArea     | Garage size in square feet |\n",
    "| GarageQual     | Garage quality |\n",
    "| GarageCond     | Garage condition |\n",
    "| PavedDrive     | Paved driveway presence |\n",
    "| WoodDeckSF     | Wood deck area in square feet |\n",
    "| OpenPorchSF    | Open porch area in square feet |\n",
    "| EnclosedPorch  | Enclosed porch area in square feet |\n",
    "| 3SsnPorch      | Three-season porch area in square feet |\n",
    "| ScreenPorch    | Screen porch area in square feet |\n",
    "| PoolArea       | Pool area in square feet |\n",
    "| PoolQC         | Pool quality |\n",
    "| Fence          | Fence quality |\n",
    "| MiscFeature    | Miscellaneous feature not covered in other categories |\n",
    "| MiscVal        | Dollar value of miscellaneous feature |\n",
    "| MoSold         | Month sold |\n",
    "| YrSold         | Year sold |\n",
    "| SaleType       | Type of sale |\n",
    "| SaleCondition  | Condition of sale |\n",
    "\n",
    "---\n",
    "\n",
    "### Access Full Codebook\n",
    "\n",
    "The link below describes what the codes mean for each of the variables.\n",
    "\n",
    "https://github.com/gdsaxton/GDAN5400/blob/main/Housing_Prices/data_description.txt\n",
    "\n",
    "\n",
    "# Machine Learning Step 1: Understanding the Problem \n",
    "\n",
    "In line with the class lecture and exercises, you now have a good sense of the first task in tackling a machine learning project: *understanding the problem*. Specifically, you understand that this is a *regression* problem requiring you to predict housing sales prices by minimizing *RMSLE*. Moreover, you have a preliminary *conceptual model* to guide your efforts. Now you are ready to start coding!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmz9dHd_ypzg"
   },
   "source": [
    "# Machine Learning Step 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "The `Exploratory Data Analysis (EDA)` stage helps uncover patterns, relationships, and potential issues within the dataset before modeling. This involves summarizing key statistics, visualizing distributions, identifying correlations, and detecting anomalies or missing values. EDA provides critical insights that guide feature selection, preprocessing strategies, and model choice. A thorough EDA ensures a deeper understanding of the data, leading to more informed decision-making in subsequent stages.\n",
    "\n",
    "#### Load the Housing Prices `Training` Dataset  \n",
    "\n",
    "I have uploaded the training and test datasets onto the class GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#http://pandas.pydata.org/pandas-docs/stable/options.html\n",
    "pd.set_option('display.max_columns', None)  #Set PANDAS to show all columns in DataFrame\n",
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/gdsaxton/GDAN5400/refs/heads/main/Housing_Prices/train.csv'\n",
    "train = pd.read_csv(train_url)\n",
    "print('# of rows in training dataset:', len(train), '\\n')\n",
    "train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run `info()` to inspect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify variables with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()[train.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Numeric Variables with Histograms  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "train.select_dtypes(include='number').hist(figsize=(13, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate an Automated Data Report  \n",
    "- Install and use `ydata-profiling` to create a detailed report of the dataset.  \n",
    "- This report will provide insights into **missing values, distributions, correlations, and more**.  \n",
    "- **Tip:** Instead of manually exploring each variable, use this **automated tool** to summarize the data in one step.  \n",
    "- Save the report as an **HTML file** for easy viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ydata-profiling\n",
    "!pip install ydata_profiling --quiet\n",
    "# Install ydata-profiling\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the report\n",
    "profile = ProfileReport(train,title=\"Housing_Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the report to an HTML file\n",
    "profile.to_file(\"housing_prices.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Step 3: Data Preprocessing and Feature Engineering\n",
    "The `Data Preprocessing & Feature Engineering` stage is crucial for ensuring that the dataset is clean, structured, and optimized for machine learning models. This involves handling missing values, encoding categorical variables, scaling numerical features, and detecting outliers. Additionally, feature engineering enhances predictive performance by creating new meaningful variables, transforming existing ones, or selecting the most relevant features. Effective preprocessing and engineering can significantly improve model accuracy and generalization.\n",
    "\n",
    "#### Example: Fill in Missing Values for `LotFrontage`\n",
    "- The `LotFrontage` column contains missing values that must be filled before modeling.  \n",
    "- Use the **median** value to replace missing values, as it is less affected by outliers.  \n",
    "- After filling in the missing values, verify that `LotFrontage` no longer has any missing entries.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in LotFrontage column:\", train[\"LotFrontage\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage'] = train['LotFrontage'].fillna(train[\"LotFrontage\"].median())\n",
    "print(\"Missing values in LotFrontage column:\", train[\"LotFrontage\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a `High_Quality` Variable\n",
    "\n",
    "From the codebook we see that the values of `OverallQual` are the following:\n",
    "\n",
    "OverallQual: Rates the overall material and finish of the house\n",
    "\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "print(\"Missing values in OverallQual column:\", train[\"OverallQual\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequencies \n",
    "train['OverallQual'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the binary variable\n",
    "train['High_Quality'] = train['OverallQual'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "train['High_Quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-tabulation to verify coding\n",
    "pd.crosstab(train['High_Quality'], train['OverallQual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "print(\"Missing values in High_Quality column:\", train[\"High_Quality\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Variable `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = 2025 - train['YearBuilt']\n",
    "train[['YearBuilt', 'Age']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "print(\"Missing values in Age column:\", train[\"Age\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Step 4: Model Selection, Training, Tuning, & Evaluation\n",
    "\n",
    "The `Model Selection, Training, Tuning, & Evaluation` stage focuses on choosing the most suitable machine learning algorithms, fitting them to the data, optimizing performance, and assessing their effectiveness. It begins with selecting baseline models and training them on the processed dataset. Hyperparameter tuning—using techniques like grid search, random search, or Bayesian optimization—helps refine model performance. Evaluation metrics such as RMSE, accuracy, or F1-score are used to measure success and compare models. This iterative process ensures that the best-performing and most generalizable model is identified for final predictions.\n",
    "\n",
    "\n",
    "#### Select Predictors and Split the Data into Testing and Training Datasets\n",
    "\n",
    "We will start with a single predictor: `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['Age']\n",
    "\n",
    "X = train[features]\n",
    "y = train['SalePrice']\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Splitting training data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Evaluate a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "\n",
    "# Define RMSLE scoring function\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, np.maximum(y_pred, 0)))  # Ensure predictions are non-negative\n",
    "\n",
    "# Initiate and run linear regression model\n",
    "model =  LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Calculate regression performance metrics\n",
    "mae = mean_absolute_error(y_val, val_predictions)\n",
    "mse = mean_squared_error(y_val, val_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(y_val, val_predictions))\n",
    "r2 = r2_score(y_val, val_predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val) \n",
    "\n",
    "# Evaluate model performance on validation data\n",
    "score = rmsle(y_val, val_predictions)\n",
    "print(\"RMSLE:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance \n",
    "\n",
    "Our regression model uses **only \"Age\" of a house** to predict **Sale Price**, and the performance metrics suggest that **Age alone is not a great predictor** of home prices. Let’s break down what these numbers mean in plain terms.\n",
    "\n",
    "---\n",
    "\n",
    "#### R² Score: 0.2898 (Weak Fit)\n",
    "- **What it means:** The model **only explains about 29% of the variation** in home prices.\n",
    "- **Why this is a problem:** This suggests that **other important factors** (like square footage, location, condition, and number of bedrooms) are missing from the model.\n",
    "- **Analogy:** Imagine trying to predict someone’s weight **using only their height**—it helps, but it’s far from perfect.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Mean Absolute Error (MAE): \\\\$51,148.47 (Large Errors)\n",
    "- **What it means:** On average, the model’s predictions are **off by about \\\\$51,000**.\n",
    "- **Why this is a problem:** In real estate, an error this large could make a big difference in pricing decisions.\n",
    "- **Example:** If a house is actually worth **\\\\$250,000**, the model might predict something like **\\\\$200,000** or **\\\\$300,000**, which is a major miss.\n",
    "\n",
    "---\n",
    "\n",
    "#### Mean Squared Error (MSE): 5.45 Billion & Root Mean Squared Error (RMSE): \\\\$73,809.45 (Even Larger Errors for Some Houses)\n",
    "- **What it means:** RMSE shows that **larger errors are even more extreme**—some predictions could be off by **\\\\$70,000 or more**.\n",
    "- **Why this is a problem:** RMSE is higher than MAE, meaning that **a few very bad predictions are pulling up the error** (the model struggles particularly with some houses).\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Root Mean Squared Logarithmic Error (RMSLE): 0.3595 (Better for Relative Errors)**\n",
    "- **What it means:** This number tells us how **far off the predictions are in percentage terms** instead of dollar amounts.\n",
    "- **Why it’s useful:** If RMSLE is **close to zero**, the model is doing well at predicting houses **relative to their actual value** (for example, predicting a \\$100,000 home as \\$110,000 is not as bad as predicting a \\$1M home as $1.1M).\n",
    "- **For comparison:** An RMSLE of **0.3595** suggests moderate errors but is **not terrible** compared to RMSE.\n",
    "\n",
    "---\n",
    "\n",
    "#### Interpreting RMSLE: 0.3595 in More Detail\n",
    "\n",
    "The **Root Mean Squared Logarithmic Error (RMSLE) = 0.3595** tells us how far off our **predictions are in percentage terms**, rather than absolute dollar differences. \n",
    "\n",
    "#### What Does RMSLE Actually Measure?\n",
    "RMSLE compares the **log-transformed actual prices** with the **log-transformed predicted prices**, then calculates the **square root of their mean squared difference**:\n",
    "\n",
    "\\\\[\n",
    "RMSLE = \\sqrt{\\frac{1}{n} \\sum \\left( \\log(1 + \\hat{y}_i) - \\log(1 + y_i) \\right)^2 }\n",
    "\\\\]\n",
    "\n",
    "Where:\n",
    "- \\\\( y_i \\\\) = actual price\n",
    "- \\\\( \\hat{y}_i \\\\) = predicted price\n",
    "- **Taking the log** helps **reduce the impact of very large errors** and focuses more on **relative differences**.\n",
    "\n",
    "#### **2. How Do We Interpret RMSLE = 0.3595?**\n",
    "Since RMSLE is a measure of **relative error**, it can be approximately interpreted as:\n",
    "\n",
    "\\\\[\n",
    "e^{0.3595} - 1 \\approx 0.432\n",
    "\\\\]\n",
    "\n",
    "This means, **on average, predictions are off by about ±43.2%** of the actual price.\n",
    "\n",
    "---\n",
    "\n",
    "#### What Does a ±43.2% Error Mean in Real Terms?\n",
    "For different price ranges, this error translates to the following **expected prediction errors**:\n",
    "\n",
    "| **Actual Sale Price** | **Typical Predicted Range** (±43.2% error) |\n",
    "|----------------------|----------------------------------|\n",
    "| **\\\\$100,000** | **\\\\$56,800 – \\\\$143,200** |\n",
    "| **\\\\$200,000** | **\\\\$113,600 – \\\\$286,400** |\n",
    "| **\\\\$300,000** | **\\\\$170,400 – \\\\$429,600** |\n",
    "| **\\\\$500,000** | **\\\\$284,000 – \\\\$716,000** |\n",
    "\n",
    "\n",
    "This means that for a house actually worth \\\\$300,000, the model might predict anything from \\\\$170K to \\\\$430K, which is a very large and impractical range.\n",
    "\n",
    "---\n",
    "\n",
    "#### How Does This Compare to Other Models?\n",
    "| **RMSLE Value** | **Interpretation** |\n",
    "|---------------|----------------|\n",
    "| **0.1 or less** | Excellent – very close predictions |\n",
    "| **0.2 - 0.3** | Good – reasonable accuracy |\n",
    "| **0.3 - 0.4** | Acceptable – useful but not great |\n",
    "| **Above 0.4** | Poor – large deviations in predictions |\n",
    "\n",
    "At **0.3595**, our model is in the **\"borderline acceptable\"** range, but it’s **not good enough for real estate pricing** because of the high variation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidebar – Calculating a Single Prediction for a 10-year-old House\n",
    "\n",
    "I will go into some technical detail here. You don't need to try to understand the math, but hopefully you will get the intuition of how we are using the \"trained\" regression model to generate new predictions. This is similar to what we covered in the lecture, but with only one predictor variable (`Age`).\n",
    "\n",
    "First, we will extract the 'intercept' (aka 'constant term') from the above regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intercept (constant term)\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Print results\n",
    "print(f\"Intercept (Constant): {intercept}\")\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(X_train.columns, coefficients):\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Now we can use those numbers to calculate the predicted sale price for a hypothetical 10-year-old house in Ames, Iowa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given updated coefficients from trained model\n",
    "intercept = 251736.368624  # β₀\n",
    "age_coefficient = -1300.9310044469596  # β₁\n",
    "\n",
    "# Input values for prediction\n",
    "age = 10  # Age of the house in years\n",
    "\n",
    "# Compute predicted sale price using the regression equation\n",
    "predicted_price = intercept + (age_coefficient * age) \n",
    "\n",
    "# Display result\n",
    "predicted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Here is a technical description of how the trained regression model uses information to generate predictions:\n",
    "\n",
    "#### Regression Equation\n",
    "\n",
    "The linear regression equation is:\n",
    "\n",
    "\\\\[\n",
    "\\hat{y} = \\beta_0 + \\beta_1 X_1\n",
    "\\\\]\n",
    "\n",
    "where:\n",
    "- \\\\( \\hat{y} \\\\) (y-hat) represents the **predicted** sale price of the house.\n",
    "- \\\\( \\beta_0 \\\\) is the **intercept** (the predicted price when all independent variables are zero).\n",
    "- \\\\( \\beta_1 \\\\) is the **coefficient** for the house age variable.\n",
    "- \\\\( X_1 \\\\) represents the **age of the house** in years.\n",
    "\n",
    "#### Substituting the Given Values:\n",
    "\n",
    "\\\\[\n",
    "\\hat{y} = 251736.37 + (-1300.93 \\times \\text{Age})\n",
    "\\\\]\n",
    "\n",
    "For a house that is 10 years old:\n",
    "\n",
    "\\\\[\n",
    "\\hat{y} = 251736.37 + (-1300.93 \\times 10)\n",
    "\\\\]\n",
    "\n",
    "\\\\[\n",
    "\\hat{y} = 251736.37 - 13009.31\n",
    "\\\\]\n",
    "\n",
    "\\\\[\n",
    "\\hat{y} = 238727.06\n",
    "\\\\]\n",
    "\n",
    "Thus, the predicted sale price for a 10-year-old house in Ames, Iowa is **\\\\$238,727.06**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Good is Our Model?\n",
    "Above, we learned that the RMSLE score is pretty average. It clearly is not a strong model. Let's look at some graphs that we can use to help identify some issues.\n",
    "\n",
    "#### Plot Actual vs. Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. actual prices\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_val, y=val_predictions, alpha=0.7)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], '--r', linewidth=2)  # Identity line\n",
    "plt.xlabel(\"Actual Sale Price\", labelpad=15)\n",
    "plt.ylabel(\"Predicted Sale Price\", labelpad=15)\n",
    "plt.title(\"Predicted vs. Actual Sale Price (Linear Regression – Age)\", pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Age vs. Actual Sale Price (with Regression Line for Predicted Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a modern Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# Create figure with better size\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Scatter plot of Age vs. Actual Sale Price\n",
    "sns.scatterplot(x=X_val['Age'], y=y_val, alpha=0.6, s=50, label=\"Actual Prices\", color=\"royalblue\")\n",
    "\n",
    "# Fit a regression line (Predicted SalePrice vs. Age) with a slightly thicker line\n",
    "sns.regplot(x=X_val['Age'], y=val_predictions, scatter=False, color=\"red\",\n",
    "            label=\"Regression Line\", line_kws={\"linewidth\": 1.5})\n",
    "\n",
    "# Select example (idx = 5)\n",
    "idx = 5  \n",
    "actual = y_val.iloc[idx]\n",
    "predicted = val_predictions[idx]\n",
    "age_value = X_val.iloc[idx]['Age']\n",
    "\n",
    "# Improve axis labels and title\n",
    "plt.xlabel(\"Age of House (Years)\", fontsize=13, labelpad=15)\n",
    "plt.ylabel(\"Sale Price ($)\", fontsize=13, labelpad=15)\n",
    "plt.title(\"Age vs. Sale Price with Regression Line\", fontsize=15, pad=20, fontweight=\"bold\")\n",
    "\n",
    "# Add a legend with a better location\n",
    "plt.legend(frameon=True, fontsize=11, loc=\"upper right\")\n",
    "\n",
    "# Show the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Age vs. Actual Sale Price, with Regression Line for Predicted Price – Highlighting One Data Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a modern Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# Create figure with better size\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Scatter plot of Age vs. Actual Sale Price\n",
    "sns.scatterplot(x=X_val['Age'], y=y_val, alpha=0.6, s=50, label=\"Actual Prices\", color=\"royalblue\")\n",
    "\n",
    "# Fit a regression line (Predicted SalePrice vs. Age) with a slightly thicker line\n",
    "sns.regplot(x=X_val['Age'], y=val_predictions, scatter=False, color=\"red\",\n",
    "            label=\"Regression Line\", line_kws={\"linewidth\": 1.5})\n",
    "\n",
    "# Select example (idx = 5)\n",
    "idx = 5  \n",
    "actual = y_val.iloc[idx]\n",
    "predicted = val_predictions[idx]\n",
    "age_value = X_val.iloc[idx]['Age']\n",
    "\n",
    "# Highlight idx = 5 with distinct colors\n",
    "plt.scatter(age_value, actual, color=\"blue\", s=50, edgecolor=\"black\", label=\"Actual (Idx 5)\", zorder=3)\n",
    "plt.scatter(age_value, predicted, color=\"red\", s=50, edgecolor=\"black\", label=\"Predicted (Idx 5)\", zorder=3)\n",
    "\n",
    "# Draw a vertical error line between actual and predicted values\n",
    "plt.plot([age_value, age_value], [actual, predicted], linestyle=\"--\", color=\"black\", linewidth=1.5)\n",
    "\n",
    "# Annotate the actual and predicted values with better positioning\n",
    "plt.text(age_value, actual - 11500, f\"Actual: {actual:,.0f}\", fontsize=11, color=\"blue\", ha=\"right\", va='top', fontweight=\"bold\")\n",
    "plt.text(age_value, predicted + 9500, f\"Predicted: {predicted:,.0f}\", fontsize=11, color=\"darkred\", ha=\"left\", va='bottom', fontweight=\"bold\")\n",
    "\n",
    "# Improve axis labels and title\n",
    "plt.xlabel(\"Age of House (Years)\", fontsize=13, labelpad=15)\n",
    "plt.ylabel(\"Sale Price ($)\", fontsize=13, labelpad=15)\n",
    "plt.title(\"Age vs. Sale Price with Regression Line\", fontsize=15, pad=20, fontweight=\"bold\")\n",
    "\n",
    "# Add a legend with a better location\n",
    "plt.legend(frameon=True, fontsize=11, loc=\"upper right\")\n",
    "\n",
    "# Show the final plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Figures\n",
    "Our scatter plots suggest that our linear regression model is **systematically underpredicting** sale prices, especially for higher-priced homes. There are a few key reasons why this might be happening:\n",
    "\n",
    "#### Feature Selection: Using Only 'Age' as a Predictor\n",
    "   - The house **age alone is likely not sufficient** to predict sale price accurately.\n",
    "   - Housing prices depend on multiple factors like square footage, number of bedrooms, location, lot size, condition, and more.\n",
    "   - The model might be too simple (high bias), leading to poor predictive performance.\n",
    "\n",
    "#### Non-Linear Relationship\n",
    "   - Housing prices **may not have a simple linear relationship with age**.\n",
    "   - Older houses could either be more valuable (historic homes) or less valuable (due to depreciation), creating **a non-monotonic relationship**.\n",
    "   - A **log transformation** on price might help capture a non-linear pattern.\n",
    "\n",
    "#### Skewed Data Distribution\n",
    "   - If sale prices have a **right-skewed distribution** (a long tail of high-priced houses), linear regression may struggle.\n",
    "   - You can check this with `sns.histplot(y, bins=50, kde=True)`.\n",
    "   - A log transformation (`np.log1p(y)`) might improve predictions.\n",
    "\n",
    "#### Heteroscedasticity\n",
    "   - The variance in errors seems to increase as actual sale price increases.\n",
    "   - This violates one of the assumptions of linear regression, leading to biased estimates.\n",
    "   - **A log-transformed regression** could stabilize variance.\n",
    "\n",
    "#### Solutions:\n",
    "1. **Add more features** (e.g., square footage, number of bedrooms, location dummy variables).\n",
    "2. **Use a log-transformed target variable:**\n",
    "   ```python\n",
    "   y = np.log1p(train['SalePrice'])\n",
    "   ```\n",
    "   And then exponentiate predictions when interpreting:\n",
    "   ```python\n",
    "   y_pred = np.expm1(model.predict(X_test))\n",
    "   ```\n",
    "3. **Try polynomial regression or non-linear models** if `Age` has a complex effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Step 5: Generate Predictions and Submitting – \n",
    "In this stage, the trained and optimized model is used to generate predictions on the test dataset. These predictions are then formatted according to the competition’s submission requirements, ensuring they align with the expected structure. Before submitting, it’s important to perform sanity checks to avoid common mistakes, such as data leakage or incorrect indexing. Once submitted, the Kaggle leaderboard provides feedback on the model’s real-world performance, helping assess its competitiveness.\n",
    "\n",
    "\n",
    "#### Make Predictions on `test.csv` and Generate Submission File\n",
    "\n",
    "Let's load the `test.csv` file from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://raw.githubusercontent.com/gdsaxton/GDAN5400/refs/heads/main/Housing_Prices/test.csv'\n",
    "test = pd.read_csv(test_url)\n",
    "print(len(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Age'] = 2025 - test['YearBuilt']\n",
    "test[['Age']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "print(\"Missing values in Age column:\", test[\"Age\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the same predictor variables as in training\n",
    "X_test = test[features]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for Kaggle test set using the trained model\n",
    "test_predictions = model.predict(X_test)\n",
    "print('# of predictions:', len(test_predictions))\n",
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure predictions are non-negative (house prices cannot be negative)\n",
    "print(f\"Min SalePrice: {test_predictions.min()}\")\n",
    "print(f\"Max SalePrice: {test_predictions.max()}\")\n",
    "\n",
    "#If there are non-negative, run the following line:\n",
    "#test_predictions = np.maximum(test_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test dataset\n",
    "test['SalePrice'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\"Id\": test[\"Id\"], \"SalePrice\": test_predictions})\n",
    "submission_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save file\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidebar – Exploring the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to see the predicted frequencies\n",
    "submission_df['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Predicted Sales Prices\n",
    "As you can see below, the histogram hints at our model not being particularly strong. We should expect a more 'normal' distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create a histogram with KDE (density) curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(submission_df['SalePrice'], bins=30, kde=True, color='royalblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted SalePrice\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Frequency\", fontsize=14, labelpad=15)\n",
    "plt.title(\"Distribution of Predicted House Prices\", fontsize=16, pad=20)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Step 6: Iterate and Improve – \n",
    "Machine learning is an iterative process, and refining the approach is key to achieving better results. After reviewing leaderboard scores and validation metrics, potential improvements—such as trying different models, engineering new features, fine-tuning hyperparameters, or adjusting preprocessing techniques—can be explored. Comparing multiple approaches and leveraging ensemble methods often lead to better generalization. Continuous iteration and learning from past submissions help enhance performance and ranking over time.\n",
    "\n",
    "### Generic Steps to Improve the Model\n",
    "#### 1. Transform Variables\n",
    "  - Log transformations `SalePrice`\n",
    "  - Normalization\n",
    "  - Standardization\n",
    "\n",
    "#### 2. Add Variables\n",
    "  - Test Different Variables \n",
    "  - \n",
    "\n",
    "#### 3. Test Different Models\n",
    "  - Instead of Linear Regression, try Decision Tree, Random Forest, XGBoost, etc.\n",
    "\n",
    "#### 4. Hyperparameter Tuning\n",
    "  - Use `GridSearchCV` to test different hyperparameters\n",
    "####\n",
    "\n",
    "#### Our Original Model with `Age` as Sole Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "features = ['Age']\n",
    "\n",
    "X = train[features]\n",
    "y = train['SalePrice']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RMSLE scoring function\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, np.maximum(y_pred, 0)))  # Ensure predictions are non-negative\n",
    "\n",
    "# Initiate and run linear regression model\n",
    "model =  LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "#Calculate RMSLE\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(y_val, val_predictions))\n",
    "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transform `SalePrice`\n",
    "Log-transforming `SalePrice` helps stabilize the variance and ensures that the model treats price differences proportionally, meaning a \\\\$10,000 increase matters more for a \\\\$100,000 house than for a \\\\$1,000,000 house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Define features\n",
    "features = ['Age']\n",
    "\n",
    "# Select independent (X) and dependent (y) variables\n",
    "X = train[features]\n",
    "y = np.log1p(train['SalePrice'])  # Apply log transformation to target variable\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RMSLE scoring function\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(np.expm1(y_true), np.expm1(y_pred)))  # Convert back to original scale\n",
    "\n",
    "# Initiate and train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Calculate RMSLE on original scale\n",
    "rmsle_value = rmsle(y_val, val_predictions)\n",
    "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transform Age\n",
    "Log-transforming `Age` helps reduce the impact of very old houses, making the relationship between age and sale price more linear and easier for the model to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Define features\n",
    "features = ['Age']\n",
    "\n",
    "# Select independent (X) and dependent (y) variables\n",
    "X = np.log1p(train[features])  # Log-transform Age\n",
    "y = train['SalePrice']\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RMSLE scoring function\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, np.maximum(y_pred, 0)))  # Ensure predictions are non-negative\n",
    "\n",
    "# Initiate and train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Calculate RMSLE\n",
    "rmsle_value = rmsle(y_val, val_predictions)\n",
    "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add More Variables\n",
    "\n",
    "Let's add the variables we modified: `LotFrontage` and `High_Quality`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "features = ['Age', 'LotFrontage', 'High_Quality']\n",
    "\n",
    "X = train[features]\n",
    "y = train['SalePrice']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RMSLE scoring function\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, np.maximum(y_pred, 0)))  # Ensure predictions are non-negative\n",
    "\n",
    "# Initiate and run linear regression model\n",
    "model =  LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "#Calculate RMSLE\n",
    "rmsle_score = np.sqrt(mean_squared_log_error(y_val, val_predictions))\n",
    "print(f\"Root Mean Squared Logarithmic Error (RMSLE): {rmsle_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis\n",
    "\n",
    "Now let's analyze *feature importance* to understand which factors have the greatest impact on house prices. This helps us *interpret the model's decisions*, prioritize key variables, and identify potential areas for improvement (e.g., adding more relevant features or transforming existing ones). By ranking coefficients, we gain insights into which characteristics buyers value most, guiding both predictive modeling and real-world decision-making in housing markets.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##### Explanation \n",
    "\n",
    "Above we have performed a *linear regression analysis* to understand how three different features (`Age`, `LotFrontage`, and `High_Quality`) influence house sale prices. Linear regression finds the best-fitting line that predicts the sale price based on these features.  \n",
    "\n",
    "The regression model assigns a *coefficient* to each feature, representing how much the sale price changes when that feature increases by one unit, *holding all else constant*. Larger coefficients (in absolute terms) indicate stronger influence on price.  \n",
    "\n",
    "Let's first create a dataframe holding the trained regression coefficients.\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\"Feature\": features, \"Coefficient\": model.coef_})\n",
    "coef_df = coef_df.sort_values(by=\"Coefficient\", key=abs, ascending=False)  # Sort by absolute value\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the Coefficients\n",
    "| Feature       | Coefficient | Interpretation |\n",
    "|--------------|------------|---------------|\n",
    "| *High_Quality* | 79,696.51 | Houses classified as \"High Quality\" sell for **\\\\$79,696 more** on average, compared to non-high-quality houses, all else being equal. This is the most important factor in the model. |\n",
    "| *LotFrontage* | 712.52 | For each additional foot of street frontage, the sale price **increases by \\\\$712.52**, assuming all other factors stay the same. |\n",
    "| *Age* | -568.40 | Each additional year of house age **reduces** the sale price by **\\\\$568.40**, meaning older houses tend to sell for less. The negative sign confirms this expected trend. |\n",
    "\n",
    "---\n",
    "\n",
    "#### **Key Takeaways**\n",
    "1. *High_Quality* has the *largest positive impact* on sale price, making it the most important factor in the model.  \n",
    "2. *LotFrontage* also has a positive effect—larger frontages increase sale prices, but its impact is much smaller than High_Quality.  \n",
    "3. *Age has a negative coefficient*, meaning older homes tend to be valued lower, though the impact is moderate.  \n",
    "\n",
    "The visualization further reinforces these insights by showing the magnitude of each coefficient. \n",
    "\n",
    "--- \n",
    "\n",
    "#### Visualization\n",
    "\n",
    "To further highlight the relative importance of the variables, lets's generate a Feature Importance Plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df, hue=\"Feature\", palette=\"Blues_r\")\n",
    "\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance (Regression Coefficients)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Models\n",
    "\n",
    "Now let's try out different models. We will test multiple machine learning models to compare their performance in predicting house prices. Instead of relying only on linear regression, we are evaluating a mix of **linear models (Ridge, Lasso, ElasticNet), tree-based models (DecisionTree, RandomForest, XGBoost), and nonlinear models (SVR)**.  \n",
    "\n",
    "By training each model on the same dataset and computing the **Root Mean Squared Logarithmic Error (RMSLE)** for validation predictions, we can determine which model generalizes best. This process helps us **identify the most accurate and robust approach** for this specific problem, guiding model selection for final predictions.  \n",
    "\n",
    "We will be using the same **train-test split and features** – `Age`, `LotFrontage`, `High_Quality` – so we will not re-run those parts of the code.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "We will test the following **eight machine learning models**:  \n",
    "\n",
    "#### **1️⃣ Linear Regression (The Straight-Line Approach)**  \n",
    "- **How it works**: Assumes that house prices change in a **straight-line relationship** with features (e.g., if `YearBuilt` goes up, price increases by a fixed amount).  \n",
    "- **Pros**: Simple, interpretable.  \n",
    "- **Cons**: Can't capture complex patterns.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2️⃣ Ridge Regression (Prevents Overfitting)**  \n",
    "- **How it works**: A linear regression model that **prevents overfitting** by reducing extreme coefficient values.  \n",
    "- **Why it's useful**: Helps stabilize predictions when features are highly correlated.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3️⃣ Lasso Regression (Feature Selection Model)**  \n",
    "- **How it works**: Similar to Ridge Regression, but **removes less important features** by shrinking some coefficients to zero.  \n",
    "- **Why it's useful**: Automatically selects the most important features, simplifying the model.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **4️⃣ ElasticNet (Balanced Regularization Model)**  \n",
    "- **How it works**: A combination of **Lasso and Ridge Regression** that balances feature selection and coefficient shrinkage.  \n",
    "- **Why it's useful**: Helps when **some features should be removed** while others need **regularization**.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **5️⃣ Decision Tree (The Rule-Based Approach)**  \n",
    "- **How it works**: Think of this model as a series of **Yes/No questions** that split the data into groups based on features.  \n",
    "  - Example: *Is the house built after 2000?* → If yes, go to the next rule.  \n",
    "- **Why it's useful**: Can handle **non-linear relationships** in the data.  \n",
    "- **Cons**: Can overfit if the tree is too deep.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 6️⃣ Random Forest (The Team Decision Tree)   \n",
    "- **How it works**: Instead of using just one decision tree, this model **combines multiple decision trees** and takes the average of their predictions.  \n",
    "- **Why it's useful**: More stable, avoids overfitting, and captures **complex relationships** in the data.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **7️⃣ XGBoost (The Smartest Tree Model)**  \n",
    "- **How it works**: Like Random Forest, but instead of treating trees equally, XGBoost **learns from mistakes** step by step.  \n",
    "- **Why it's useful**: Often one of the **most powerful models** for structured data.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **8️⃣ Support Vector Regression (SVR)**  \n",
    "- **How it works**: Instead of fitting a single best-fit line, SVR finds a **small range (margin)** where most predictions will fall.  \n",
    "- **Why it's useful**: Handles **nonlinear relationships** better than standard regression.  \n",
    "- **Cons**: Can be slower on large datasets and performed worst in our analysis.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **📊 Summary of Models**\n",
    "| Model | Purpose |\n",
    "|-------|---------|\n",
    "| **Linear Regression** | Baseline model, assumes a linear relationship | \n",
    "| **Ridge Regression** | Prevents overfitting by **shrinking coefficients** |\n",
    "| **Lasso Regression** | Shrinks **and removes** irrelevant features | \n",
    "| **ElasticNet** | Balances **feature selection (L1) and shrinkage (L2)** | \n",
    "| **Decision Tree** | Splits data using **rule-based conditions** | \n",
    "| **Random Forest** | Uses **multiple decision trees** to improve stability | \n",
    "| **XGBoost** | Learns from **previous mistakes** to improve predictions | \n",
    "| **SVR** | Uses a **flexible margin** instead of a single line | \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Key Question: Which Model Will Perform Best?\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "1. **Define a dictionary of models (`models`)**  \n",
    "   - Several regression models are stored in a dictionary with their names as keys and model objects as values.  \n",
    "   - Models include **Linear Regression, Ridge, Lasso, ElasticNet, Decision Tree, Random Forest, XGBoost, and SVR**.  \n",
    "\n",
    "2. **Create an empty list (`results`)**  \n",
    "   - This list will store the performance of each model.  \n",
    "\n",
    "3. **Loop through each model, train it, and evaluate it**  \n",
    "   - For each model:  \n",
    "     - It is trained using `X_train` and `y_train`.  \n",
    "     - It makes predictions on `X_val` (validation data).  \n",
    "     - The **Root Mean Squared Logarithmic Error (RMSLE)** is calculated to measure model performance.  \n",
    "     - The model's name and its RMSLE score are added to the `results` list.  \n",
    "\n",
    "4. **Convert results into a Pandas DataFrame (`results_df`)**  \n",
    "   - The results are stored in a DataFrame and sorted in **ascending order by RMSLE**, so the best-performing model appears first.  \n",
    "   \n",
    "#### **Why Are We Doing This?**  \n",
    "This approach allows us to **compare multiple models efficiently** and determine which one gives the best predictions for house prices. It helps us make an informed decision on **which model to use in the final analysis**.     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Define models with default parameters\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'DecisionTree': DecisionTreeRegressor(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'XGBoost': XGBRegressor(verbosity=0),\n",
    "    'SVR': SVR(),\n",
    "}\n",
    "\n",
    "# Create empty list for storing results\n",
    "results = []\n",
    "\n",
    "#Train each model in a loop, saving model name RMSLE score into results dataframe\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmsle_score = rmsle(y_val, y_pred)\n",
    "    results.append({'Model': name, 'RMSLE': rmsle_score})\n",
    "\n",
    "# Convert results to DataFrame; sort by RMSLE and output\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('RMSLE')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Model Performance\n",
    "\n",
    "- **🏆 Best Overall Model** → **Random Forest** (lowest RMSLE).  \n",
    "- **Worst Model** → **SVR** (highest RMSLE).  \n",
    "- **Tree-based models (Random Forest, XGBoost, Decision Tree) outperformed linear models.**  \n",
    "- **Regularized linear models (Ridge, Lasso, ElasticNet) performed similarly.**  \n",
    "\n",
    "---\n",
    "\n",
    "#### Takeaways\n",
    "\n",
    "- **Random Forest** was the best-performing model for this dataset.  \n",
    "- **Tree-based models** (Random Forest, XGBoost, Decision Tree) captured complex patterns better than linear models.  \n",
    "- **Regularized linear models (Ridge, Lasso, ElasticNet) performed similarly** and were slightly better than standard Linear Regression.  \n",
    "- **SVR performed the worst**, likely due to computational inefficiency and the dataset's characteristics.  \n",
    "- **Feature selection matters**—adding more meaningful features (e.g., neighborhood, number of bathrooms) could improve accuracy.  \n",
    "\n",
    "**Next Steps:** Try adding more meaningful features and/or hyperparameter tuning, to further improve accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the Best Model for Generating Updated Submission File\n",
    "First, select the best model and re-generate predictions on `validation` dataset without retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the trained model without retraining\n",
    "model = models['RandomForest']   # No re-fitting, just using the stored model\n",
    "#model.fit(X_train, y_train)  #If you want to retrain the model, uncomment this line\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val) # Model is already trained, just predict\n",
    "\n",
    "# Evaluate model performance on validation data\n",
    "rmsle_score = rmsle(y_val, val_predictions)\n",
    "print(\"RMSLE:\", rmsle_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Alternative: Extract best model from `results_df` programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best model from results_df based on lowest RMSLE\n",
    "best_model_name = results_df.loc[results_df['RMSLE'].idxmin(), 'Model']\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "model = models[best_model_name] # No re-fitting, just using the stored model\n",
    "#model.fit(X_train, y_train)  #If you want to retrain the model, uncomment this line\n",
    "\n",
    "# Generate predictions on validation set\n",
    "val_predictions = model.predict(X_val) # Model is already trained, just predict\n",
    "\n",
    "# Evaluate model performance on validation data\n",
    "rmsle_score = rmsle(y_val, val_predictions)\n",
    "print(\"RMSLE:\", rmsle_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Updated Predictions on `test.csv` and Submission File\n",
    "Now we can apply the model to `test.csv`. We'll also reproduce the descriptives and the histogram to see if our distribution of predicted `SalePrice` has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the binary variable\n",
    "test['High_Quality'] = test['OverallQual'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "test['High_Quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in High_Quality column:\", test[\"High_Quality\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['LotFrontage'] = test['LotFrontage'].fillna(test[\"LotFrontage\"].median())\n",
    "print(\"Missing values in LotFrontage column:\", test[\"LotFrontage\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the same predictor variables as in training\n",
    "X_test = test[features]\n",
    "X_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for Kaggle test set using the trained model\n",
    "test_predictions = model.predict(X_test)\n",
    "print('# of predictions:', len(test_predictions))\n",
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure predictions are non-negative (house prices cannot be negative)\n",
    "print(f\"Min SalePrice: {test_predictions.min()}\")\n",
    "print(f\"Max SalePrice: {test_predictions.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test dataset\n",
    "test['SalePrice'] = test_predictions\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\"Id\": test[\"Id\"], \"SalePrice\": test_predictions})\n",
    "submission_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save file\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to see the predicted frequencies\n",
    "submission_df['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create a histogram with KDE (density) curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(submission_df['SalePrice'], bins=30, kde=True, color='royalblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted SalePrice\", fontsize=14, labelpad=15)\n",
    "plt.ylabel(\"Frequency\", fontsize=14, labelpad=15)\n",
    "plt.title(\"Distribution of Predicted House Prices\", fontsize=16, pad=20)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 29507,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "035809f5dfaf449dad35f7577b30ea1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f40670003aa4b3d87bdae162f3dc6b5",
      "placeholder": "​",
      "style": "IPY_MODEL_3a5a15f344e54cefb9332bf5a0eff466",
      "value": " 47/47 [00:05&lt;00:00,  5.36it/s, Completed]"
     }
    },
    "0f40670003aa4b3d87bdae162f3dc6b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13e0ba926f2f4ead85a85d6d6467e911": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21483ffb63cc45388b23ec7e101b6b09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "228e72349ee74b54adcc6aedfb83d282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27caea6456a9430e97b54a5014bbc241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "291c2de1a99543fe8dc48394af560635": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30e2c17ffeeb4a538e3f81804b3f405c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3127f65572d04d3f851f5192800559b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_891d8203302c49ee901c8cfdec800480",
      "placeholder": "​",
      "style": "IPY_MODEL_590cd830f98a445b8b8ff661a6f1e520",
      "value": "Summarize dataset: 100%"
     }
    },
    "3a5a15f344e54cefb9332bf5a0eff466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "438248e5c9b74ce99a98ae5620b7d982": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45ef0bf3b41e4e4eaae21ee33d208ec0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e08a134cadd4478aac25ba96473a701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3127f65572d04d3f851f5192800559b1",
       "IPY_MODEL_a8c1ec8b30364d4eb68487acdc477b03",
       "IPY_MODEL_035809f5dfaf449dad35f7577b30ea1a"
      ],
      "layout": "IPY_MODEL_45ef0bf3b41e4e4eaae21ee33d208ec0"
     }
    },
    "516df8813ad44eb396d323da89b157ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_863516548a7644029f481ee2078fec6b",
      "placeholder": "​",
      "style": "IPY_MODEL_27caea6456a9430e97b54a5014bbc241",
      "value": " 1/1 [00:00&lt;00:00, 30.25it/s]"
     }
    },
    "53576e5b381541599b222dd3daa81d92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dfea0518ee34f4eb55dfa8deb36c879",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5bca48df542b408cb2de7fdf1befaa1c",
      "value": 1
     }
    },
    "55c10e963e074b6dacae7336b10a83f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "590cd830f98a445b8b8ff661a6f1e520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bca48df542b408cb2de7fdf1befaa1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "605c1594e11b4791ac6046d2436075cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "630b7f6abc43402687310d5a1a8dee11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30e2c17ffeeb4a538e3f81804b3f405c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_228e72349ee74b54adcc6aedfb83d282",
      "value": 1
     }
    },
    "69946cb0bbfe4bd2a7e919a3dfdc0eb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aa99e9c5308426788d222b4df29cc44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f3c03ba852c4d1ab1027711601be623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75e2c39a711f411a9384ee9740a444f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69946cb0bbfe4bd2a7e919a3dfdc0eb9",
      "placeholder": "​",
      "style": "IPY_MODEL_a20842cf85514f8f928220e80d5d754f",
      "value": "Render HTML: 100%"
     }
    },
    "7dfea0518ee34f4eb55dfa8deb36c879": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81f09abf8e53446d9d5f905d17563a60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "863516548a7644029f481ee2078fec6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891d8203302c49ee901c8cfdec800480": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95c88d8655634e4485ecd69c06cedaf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21483ffb63cc45388b23ec7e101b6b09",
      "placeholder": "​",
      "style": "IPY_MODEL_81f09abf8e53446d9d5f905d17563a60",
      "value": " 1/1 [00:01&lt;00:00,  1.32s/it]"
     }
    },
    "9cc3f606fdda41428a2b565b70cffdb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a20842cf85514f8f928220e80d5d754f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2e677b111864535b01aeec28b396db0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75e2c39a711f411a9384ee9740a444f7",
       "IPY_MODEL_dc16db812ba046cfb4ebb5f07e0fec04",
       "IPY_MODEL_95c88d8655634e4485ecd69c06cedaf2"
      ],
      "layout": "IPY_MODEL_438248e5c9b74ce99a98ae5620b7d982"
     }
    },
    "a596ff23b7de4922b2eedfa5bf3ccc02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8c1ec8b30364d4eb68487acdc477b03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a596ff23b7de4922b2eedfa5bf3ccc02",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9cc3f606fdda41428a2b565b70cffdb1",
      "value": 5
     }
    },
    "b4d6553c1eea4375ae9d090eae8f423b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c660a50ffa754a97881ec7743f33b417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_605c1594e11b4791ac6046d2436075cb",
      "placeholder": "​",
      "style": "IPY_MODEL_6aa99e9c5308426788d222b4df29cc44",
      "value": " 1/1 [00:07&lt;00:00,  7.23s/it]"
     }
    },
    "d1e5a065932f4a518b5c2ef9003be9b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d29df846cca644fca527ca1571c7b89e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6d72e6822654cbeb7375a5ff7d2ed07",
       "IPY_MODEL_630b7f6abc43402687310d5a1a8dee11",
       "IPY_MODEL_516df8813ad44eb396d323da89b157ea"
      ],
      "layout": "IPY_MODEL_b4d6553c1eea4375ae9d090eae8f423b"
     }
    },
    "d6d72e6822654cbeb7375a5ff7d2ed07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13e0ba926f2f4ead85a85d6d6467e911",
      "placeholder": "​",
      "style": "IPY_MODEL_feccc05eb2184c1b8646ec28593ecb4a",
      "value": "Export report to file: 100%"
     }
    },
    "dc16db812ba046cfb4ebb5f07e0fec04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1e5a065932f4a518b5c2ef9003be9b7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_291c2de1a99543fe8dc48394af560635",
      "value": 1
     }
    },
    "e4aaf95258d64d43947e12a43a24aa49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea93d9885edb4998833cf8d25bdfaa7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55c10e963e074b6dacae7336b10a83f1",
      "placeholder": "​",
      "style": "IPY_MODEL_e4aaf95258d64d43947e12a43a24aa49",
      "value": "Generate report structure: 100%"
     }
    },
    "f692741bffb647d88547735a9b1b82f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea93d9885edb4998833cf8d25bdfaa7c",
       "IPY_MODEL_53576e5b381541599b222dd3daa81d92",
       "IPY_MODEL_c660a50ffa754a97881ec7743f33b417"
      ],
      "layout": "IPY_MODEL_6f3c03ba852c4d1ab1027711601be623"
     }
    },
    "feccc05eb2184c1b8646ec28593ecb4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
