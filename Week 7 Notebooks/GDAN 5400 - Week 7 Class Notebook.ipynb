{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\"https://colab.research.google.com/github/gdsaxton/GDAN5400/blob/main/Week%207%20Notebooks/GDAN%205400%20-%20Week%207%20Class%20Notebook.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" /></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhVl74Q9kMuG"
   },
   "source": [
    "# Introduction to Kaggle Competitions\n",
    "\n",
    "Logging into Kaggle for the first time can be daunting. The competitions often have large cash prizes, public leaderboards, and involve complex data. Nevertheless, all data scientists can rapidly learn from machine learning competitions and meaningfully contribute to our community. To give you a clear understanding of how our platform works and a mental model of the type of learning you could do on Kaggle, Kaggle has created a Getting Started tutorial for the Titanic competition. It walks you through the initial steps required to get your first decent submission on the leaderboard. I have modified the tutorial for clarity and aslo for working in the Google Colab environment. By the end of the tutorial, you'll also have a solid understanding of how to train your own machine learning model and upload your predictions to the Kaggle.\n",
    "\n",
    "# **What is Kaggle?**\n",
    "\n",
    "Kaggle is an online platform for data science and machine learning where users can:\n",
    "- Access **datasets** for analysis and modeling.\n",
    "- Participate in **competitions** to solve real-world problems.\n",
    "- Share and explore **notebooks** (Python, R) created by other users.\n",
    "- Learn from **courses** on machine learning, deep learning, and AI.\n",
    "- Collaborate with a global community of data scientists.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features\n",
    "- **Kaggle Datasets** ‚Äì A large collection of public datasets for various domains.  \n",
    "- **Kaggle Competitions** ‚Äì Data science challenges with prize money and rankings.  \n",
    "- **Kaggle Notebooks** ‚Äì Cloud-based Jupyter notebooks for coding and sharing work.  \n",
    "- **Kaggle Discussions** ‚Äì Forums to interact with the community and learn from experts.  \n",
    "- **Kaggle Courses** ‚Äì Free courses on Python, ML, deep learning, and more.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use Kaggle?\n",
    "- **Learn & Practice** ‚Äì Beginner-friendly platform for hands-on machine learning.  \n",
    "- **Compete & Improve** ‚Äì Solve complex problems and benchmark against top data scientists.  \n",
    "- **Collaborate & Share** ‚Äì Work with teams, explore notebooks, and exchange ideas.  \n",
    "- **Access Free Compute** ‚Äì Use Kaggle‚Äôs free GPUs/TPUs for deep learning projects.  \n",
    "\n",
    "Explore Kaggle: [https://www.kaggle.com](https://www.kaggle.com)\n",
    "\n",
    "\n",
    "\n",
    "# First Step : Join the competition!\n",
    "\n",
    "The first thing to do is to join the competition!  Open a new window with **[the competition page](https://www.kaggle.com/c/titanic)**, and click on the **\"Join Competition\"** button, if you haven't already.  (_If you see a \"Submit Predictions\" button instead of a \"Join Competition\" button, you have already joined the competition, and don't need to do so again._)\n",
    "\n",
    "![](https://i.imgur.com/07cskyU.png)\n",
    "\n",
    "This takes you to the rules acceptance page.  You must accept the competition rules in order to participate.  These rules govern how many submissions you can make per day, the maximum team size, and other competition-specific details.   Then, click on **\"I Understand and Accept\"** to indicate that you will abide by the competition rules.\n",
    "\n",
    "# The Challenge\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered ‚Äúunsinkable‚Äù RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren‚Äôt enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: ‚Äúwhat sorts of people were more likely to survive?‚Äù using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\n",
    "`The competition is simple: we want you to use the Titanic passenger data (name, age, price of ticket, etc) to try to predict who will survive and who will die.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhVl74Q9kMuG"
   },
   "source": [
    "# The Data\n",
    "\n",
    "To take a look at the competition data, click on the **<a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\" rel=\"noopener noreferrer\"><b>Data tab</b></a>** at the top of the competition page.  Then, scroll down to find the list of files.\n",
    "\n",
    "There are three files in the data: (1) **train.csv**, (2) **test.csv**, and (3) **gender_submission.csv**.\n",
    "\n",
    "### (1) train.csv\n",
    "\n",
    "**train.csv** contains the details of a subset of the passengers on board (891 passengers, to be exact -- where each passenger gets a different row in the table). Importantly, this dataset reveals whether they survived or not, also known as the **\"ground truth\"**.\n",
    "\n",
    "\n",
    "To investigate this data, go to the Kaggle competition page and click on the name of the file on the left of the screen.  Once you've done this, you can view all of the data in the window.  \n",
    "\n",
    "![](https://i.imgur.com/cYsdt0n.png)\n",
    "\n",
    "The values in the second column (**\"Survived\"**) can be used to determine whether each passenger survived or not:\n",
    "- if it's a \"1\", the passenger survived.\n",
    "- if it's a \"0\", the passenger died.\n",
    "\n",
    "For instance, the first passenger listed in **train.csv** is Mr. Owen Harris Braund.  He was 22 years old when he died on the Titanic.\n",
    "\n",
    "**train.csv** will contain the details of a subset of the passengers on board (**891 to be exact**) and, importantly, will reveal whether they survived or not, also known as the **\"ground truth\"**.\n",
    "\n",
    "\n",
    "\n",
    "### (2) test.csv\n",
    "\n",
    "Using the patterns you find in **train.csv**, you have to predict whether the other 418 passengers on board (in **test.csv**) survived.  \n",
    "\n",
    "When you are on the Kaggle competition page, click on **test.csv** (on the left of the screen) to examine its contents.  Note that **test.csv** does not have a **\"Survived\"** column - this information is hidden from you, and how well you do at predicting these hidden values will determine how highly you score in the competition!\n",
    "\n",
    "### (3) gender_submission.csv\n",
    "\n",
    "The **gender_submission.csv** file is provided as an example that shows how you should structure your predictions.  It predicts that all female passengers survived, and all male passengers died.  Your hypotheses regarding survival will probably be different, which will lead to a different submission file.  But, just like this file, your submission should have:\n",
    "- a **\"PassengerId\"** column containing the IDs of each passenger from **test.csv**.\n",
    "- a **\"Survived\"** column (that you will create!) with a \"1\" for the rows where you think the passenger survived, and a \"0\" where you predict that the passenger died."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Kaggle‚Äôs Competitions Work\n",
    "\n",
    "### Join the Competition\n",
    "Read about the challenge description, accept the Competition Rules, and gain access to the competition dataset.\n",
    "\n",
    "### Get to Work\n",
    "Download the data, build models on it locally or on **Kaggle Notebooks** (our no-setup, customizable Jupyter Notebooks environment with free GPUs) and generate a prediction file.\n",
    "\n",
    "### Make a Submission\n",
    "Upload your prediction as a submission on Kaggle and receive an accuracy score.\n",
    "\n",
    "### Check the Leaderboard\n",
    "See how your model ranks against other Kagglers on our leaderboard.\n",
    "\n",
    "### Improve Your Score\n",
    "Check out the [discussion forum](https://www.kaggle.com/c/titanic/discussion?sort=hotness) to find lots of tutorials and insights from other competitors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Goal\n",
    "It is your job to predict if a passenger survived the sinking of the Titanic or not.  \n",
    "For each passenger in the test set, you must predict a `0` or `1` value for the variable.\n",
    "\n",
    "### Metric\n",
    "Your score is the percentage of passengers you correctly predict. This is known as [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I‚Äôm ready to get started. Where do I get help if I need it?\n",
    "\n",
    "#### For Competition Help: Titanic Discussion Forum  \n",
    "Kaggle doesn‚Äôt have a dedicated team to help troubleshoot your code, so you‚Äôll typically find that you receive a response more quickly by asking your question in the appropriate forum.  \n",
    "\n",
    "The forums are full of useful information on the **data, metric, and different approaches**. We encourage you to use the forums often. If you share your knowledge, you'll find that others will share a lot in turn!  \n",
    "\n",
    "üîó [Titanic Discussion Forum](https://www.kaggle.com/c/titanic/discussion?sort=hotness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Packages and Set up Notebook Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "id": "mGYOtcS5kMuH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#http://pandas.pydata.org/pandas-docs/stable/options.html\n",
    "pd.set_option('display.max_columns', None)  #Set PANDAS to show all columns in DataFrame\n",
    "pd.set_option('max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8-pUwZeydEn"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "I have downloaded the data and put them into the `GDAN 5400` folder on GitHub in order to facilitate easy access. \n",
    "\n",
    "How I got the URL for the file:\n",
    "- Locate the CSV file in the GitHub repository.\n",
    "- Click on the file to view its contents.\n",
    "- Click the \"Raw\" button, typically found in the upper right corner of the file view. This will display the raw CSV data.\n",
    "- Copy the URL of the raw CSV file.\n",
    "- In your Google Colab notebook, use the pandas library to read the CSV file directly from the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "Pnk4KE6HvGZH",
    "outputId": "a5aa3565-4940-4734-f4d8-4d96b5e08f38"
   },
   "outputs": [],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/gdsaxton/GDAN5400/refs/heads/main/Titanic/train.csv'\n",
    "train = pd.read_csv(train_url)\n",
    "print('# of rows in training dataset:', len(train), '\\n')\n",
    "train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| **Data Dictionary** |   |   |\n",
    "|---------------------|---|---|\n",
    "| **Variable**       | **Definition**                         | **Key**                                   |\n",
    "| Survived          | Survival                              | 0 = No, 1 = Yes                          |\n",
    "| Pclass            | Ticket class                          | 1 = 1st, 2 = 2nd, 3 = 3rd                |\n",
    "| Sex               | Sex                                   |                                           |\n",
    "| Age               | Age in years                          |                                           |\n",
    "| SibSp             | # of siblings/spouses aboard Titanic |                                           |\n",
    "| Parch             | # of parents/children aboard Titanic |                                           |\n",
    "| Ticket            | Ticket number                         |                                           |\n",
    "| Fare              | Passenger fare                        |                                           |\n",
    "| Cabin             | Cabin number                          |                                           |\n",
    "| Embarked          | Port of Embarkation                   | C = Cherbourg, Q = Queenstown, S = Southampton |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "html_table = \"\"\"\n",
    "<table style=\"border-collapse: collapse; width: 100%; text-align: left; font-size: 14px; border: 1px solid #ddd;\">\n",
    "    <tr style=\"background-color: #003366; color: white; font-size: 20px; text-align: center;\">\n",
    "        <th colspan=\"3\" style=\"padding: 12px; text-align: center;\">Data Dictionary</th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #004466; color: white;\">\n",
    "        <th style=\"padding: 8px; border: 1px solid #ddd;\">Variable</th>\n",
    "        <th style=\"padding: 8px; border: 1px solid #ddd;\">Definition</th>\n",
    "        <th style=\"padding: 8px; border: 1px solid #ddd;\">Key</th>\n",
    "    </tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Survived</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Survival</td><td style=\"padding: 8px; border: 1px solid #ddd;\">0 = No, 1 = Yes</td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Pclass</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Ticket class</td><td style=\"padding: 8px; border: 1px solid #ddd;\">1 = 1st, 2 = 2nd, 3 = 3rd</td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Sex</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Sex</td><td style=\"padding: 8px; border: 1px solid #ddd;\"></td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Age</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Age in years</td><td style=\"padding: 8px; border: 1px solid #ddd;\"></td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">SibSp</td><td style=\"padding: 8px; border: 1px solid #ddd;\"># of siblings/spouses aboard Titanic</td><td style=\"padding: 8px; border: 1px solid #ddd;\"></td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Parch</td><td style=\"padding: 8px; border: 1px solid #ddd;\"># of parents/children aboard Titanic</td><td style=\"padding: 8px; border: 1px solid #ddd;\"></td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Ticket</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Ticket number</td><td style=\"padding: 8px; border: 1px solid #ddd;\"></td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Fare</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Passenger fare</td><td style=\"padding: 8px; border: 1px solid #ddd;\"></td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Cabin</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Cabin number</td><td style=\"padding: 8px; border: 1px solid #ddd;\"></td></tr>\n",
    "    <tr><td style=\"padding: 8px; border: 1px solid #ddd;\">Embarked</td><td style=\"padding: 8px; border: 1px solid #ddd;\">Port of Embarkation</td><td style=\"padding: 8px; border: 1px solid #ddd;\">C = Cherbourg, Q = Queenstown, S = Southampton</td></tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmz9dHd_ypzg"
   },
   "source": [
    "# Data exploration\n",
    "e.g., histogram, correlations, df.info(),.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QsJWWmgOypp-",
    "outputId": "626d7696-7dd0-4bbb-cb0a-a0de38d2c0d7"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_e4YUu5hypM3",
    "outputId": "02de05dd-d4a4-4823-894c-845f04edc40a"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_e4YUu5hypM3",
    "outputId": "02de05dd-d4a4-4823-894c-845f04edc40a"
   },
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "c4q4I5vMyo9t",
    "outputId": "4cb4ca74-410c-408b-a918-f56489e2dff4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "train.select_dtypes(include='number').hist(figsize=(13, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLkWSA14zGkt",
    "outputId": "e83f2a2b-b9c1-4982-821b-c16f2e2ff27e"
   },
   "outputs": [],
   "source": [
    "!pip install ydata_profiling --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLkWSA14zGkt",
    "outputId": "e83f2a2b-b9c1-4982-821b-c16f2e2ff27e"
   },
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vpv_yklzJLW"
   },
   "outputs": [],
   "source": [
    "# Generate the report\n",
    "profile = ProfileReport(train,title=\"Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d29df846cca644fca527ca1571c7b89e",
      "d6d72e6822654cbeb7375a5ff7d2ed07",
      "630b7f6abc43402687310d5a1a8dee11",
      "516df8813ad44eb396d323da89b157ea",
      "b4d6553c1eea4375ae9d090eae8f423b",
      "13e0ba926f2f4ead85a85d6d6467e911",
      "feccc05eb2184c1b8646ec28593ecb4a",
      "30e2c17ffeeb4a538e3f81804b3f405c",
      "228e72349ee74b54adcc6aedfb83d282",
      "863516548a7644029f481ee2078fec6b",
      "27caea6456a9430e97b54a5014bbc241"
     ]
    },
    "id": "97bBWqnR3HoZ",
    "outputId": "8b458519-0dae-4eea-b606-d7896aa0c7b6"
   },
   "outputs": [],
   "source": [
    "# Save the report to .html\n",
    "profile.to_file(\"titanic.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_Dbqhm-kMuI"
   },
   "source": [
    "#  Explore a pattern and make a submission\n",
    "\n",
    "Remember our goal: we want to find patterns in **train.csv** that help us predict whether the passengers in **test.csv** survived.\n",
    "\n",
    "It might initially feel overwhelming to look for patterns, when there's so much data to sort through.  So, we'll start simple.\n",
    "\n",
    "### Explore a pattern ‚Äì `Sex`\n",
    "\n",
    "Remember that the sample submission file in **gender_submission.csv** assumes that all female passengers survived (and all male passengers died).  \n",
    "\n",
    "Is this a reasonable first guess?  We'll check if this pattern holds true in the data (in **train.csv**).\n",
    "\n",
    "Copy the code below into a new code cell.  Then, run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-4JulNtkMuI",
    "outputId": "80e2df5e-e009-41ac-b35d-596a661680d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "women = train.loc[train.Sex == 'female'][\"Survived\"]\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8lqTe9ckMuI"
   },
   "source": [
    "The code above calculates the percentage of female passengers (in **train.csv**) who survived.\n",
    "\n",
    "Then, run the code below in another code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXm5pQ9wkMuI",
    "outputId": "ee7c2a42-de79-4dcd-b69a-5d1bb09ec63e"
   },
   "outputs": [],
   "source": [
    "men = train.loc[train.Sex == 'male'][\"Survived\"]\n",
    "rate_men = sum(men)/len(men)\n",
    "\n",
    "print(\"% of men who survived:\", rate_men)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjWdXHP5kMuJ"
   },
   "source": [
    "The code above calculates the percentage of male passengers (in **train.csv**) who survived.\n",
    "\n",
    "From this you can see that just over 74% of the women on board survived, whereas only 19% of the men lived to tell about it. Since gender seems to be such a strong indicator of survival, the submission file in **gender_submission.csv** is not a bad first guess!\n",
    "\n",
    "But at the end of the day, this gender-based submission bases its predictions on only a single column.  As you can imagine, by considering multiple columns, we can discover more complex patterns that can potentially yield better-informed predictions.  Since it is quite difficult to consider several columns at once (or, it would take a long time to consider all possible patterns in many different columns simultaneously), we'll use machine learning to automate this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhHdCpcTAW5C"
   },
   "source": [
    "### Digging Deeper ‚Äì Contingency Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "QywKrR2wn4zb",
    "outputId": "0cf5cfa4-5d66-4400-c279-2d9d6fe50cc4"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(train['Survived'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create crosstab\n",
    "ct = pd.crosstab(train['Survived'], train['Sex'])\n",
    "\n",
    "# Add row totals\n",
    "ct['Total'] = ct.sum(axis=1)\n",
    "\n",
    "# Add column totals\n",
    "ct.loc['Total'] = ct.sum()\n",
    "\n",
    "# Calculate percentages\n",
    "col_pct = (ct.div(ct.iloc[-1]) * 100).round(1)\n",
    "row_pct = (ct['Total']/ct.loc['Total', 'Total'] * 100).round(1)\n",
    "\n",
    "# Create MultiIndex for columns\n",
    "arrays = [\n",
    "    ['Female', 'Female', 'Male', 'Male', 'Total', 'Total'],\n",
    "    ['N', '%', 'N', '%', 'N', '%']\n",
    "]\n",
    "tuples = list(zip(*arrays))\n",
    "column_index = pd.MultiIndex.from_tuples(tuples)\n",
    "\n",
    "# Create DataFrame with multi-level columns\n",
    "data = np.column_stack([\n",
    "    ct['female'],\n",
    "    col_pct['female'].map('{:.1f}%'.format),\n",
    "    ct['male'],\n",
    "    col_pct['male'].map('{:.1f}%'.format),\n",
    "    ct['Total'],\n",
    "    row_pct.map('{:.1f}%'.format)\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(data, columns=column_index,\n",
    "                 index=['Did not survive', 'Survived', 'Total'])\n",
    "\n",
    "# Center align headers\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Logistic Regression with the Titanic Dataset\n",
    "\n",
    "In this mini-tutorial, we'll explore logistic regression using the famous Titanic dataset, focusing specifically on how passenger age affected survival probability.\n",
    "\n",
    "### What is Logistic Regression?\n",
    "Logistic regression is used when we want to predict a binary outcome (in this case, survived or didn't survive) based on one or more predictors (in this case, age). Unlike linear regression which gives us a continuous output, logistic regression gives us probabilities between 0 and 1.\n",
    "\n",
    "\n",
    "Logistic regression requires that there be no missing values in the independent variable (Age in this case).\n",
    "\n",
    "#### Drop Missing Age Values\n",
    "To ensure that our logistic regression model does not include missing values in the `Age` column, we will drop any rows where `Age` is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6YPNDCzAWiN",
    "outputId": "dd8dd711-3704-4406-de6f-b365ee7eb239"
   },
   "outputs": [],
   "source": [
    "X = train.dropna(subset=['Age'])[['Age']]     # Independent variable\n",
    "y = train.dropna(subset=['Age'])['Survived']  # Target variable (0 = No, 1 = Yes)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DwhfZ-bzEoSv",
    "outputId": "a37d2858-b50f-4319-ebf9-7fe59dc27e24"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#Since statsmodels does not automatically add an intercept (constant) term like Scikit-Learn does, we need to do it manually:\n",
    "X = sm.add_constant(X)  # Adds a column of 1s for the intercept\n",
    "logit_model = sm.Logit(y, X)  # Fit the logistic regression model\n",
    "result = logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output ‚Äì  `statsmodels` Output Explained\n",
    "When you run the statsmodels version, you get a detailed statistical summary. Here's what the key parts mean:\n",
    "\n",
    "- `coef`: The coefficient for age. A negative coefficient means survival probability decreases with age\n",
    "- `std err`: How uncertain we are about the coefficient\n",
    "- `z`: The z-statistic (coefficient divided by std err)\n",
    "- `P>|z|`: The p-value. If less than 0.05, we say age has a \"statistically significant\" effect on survival\n",
    "` `Pseudo R-squared`: How well our model fits the data (higher is better, but don't expect values like regular R-squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use our results to make survival predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "c6qiEgVBF5rD",
    "outputId": "535ed2b4-3417-4edd-d952-5d978c33f99a"
   },
   "outputs": [],
   "source": [
    "result.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D21c4bUjKlM5"
   },
   "source": [
    "## The Big Picture\n",
    "- Parallel to betting/gambling: \"If I told you a 5-year-old and an 80-year-old were on the Titanic, would you bet the same amount on their survival?\"\n",
    "- We are predicting *probabilities* of survival, not definitely saying who lived or died."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Vs-fN1zEa1W"
   },
   "source": [
    "# Alternative: `sklearn` Output Explained\n",
    "The sklearn version gives us just the basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3racI0SdEYGN",
    "outputId": "6e93a845-211f-4c96-bc01-46d8685a9681"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Prepare data - drop missing values and get X and y\n",
    "df = train.dropna(subset=['Age'])\n",
    "#X = df['Age']\n",
    "#We need to convert X to a 2D array using .values.reshape(-1, 1). This transforms the pandas Series into a numpy array and reshapes it so each value is in its own row.\n",
    "X = df[['Age']]\n",
    "#Note the double bracked on df in the preceding line. This keeps X in DataFrame format instead of a Series. LogisticRegression() LogisticRegression expects X as a 2D array, even for a single predictor.\n",
    "#Below is an alternative for cases like this where we have a single predictor.\n",
    "#X = df[['Age']].values.reshape(-1, 1)  # Convert to 2D array ‚Äì¬†reshapes it into the correct format where each row represents one data point.\n",
    "y = df['Survived']\n",
    "\n",
    "# Fit model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print coefficients\n",
    "print('Intercept:', model.intercept_[0])\n",
    "print('Age coefficient:', model.coef_[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0N086K7I9QQ"
   },
   "source": [
    "This gives us the basic coefficients. If the age coefficient is negative, it means older passengers were less likely to survive. If positive, older passengers were more likely to survive.\n",
    "\n",
    "- `Intercept`: The log-odds of survival when age = 0 (not very meaningful here)\n",
    "- `Age coefficient`: How much the log-odds of survival change for each year increase in age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihdB9_BoA4c6"
   },
   "source": [
    "- The coefficients (like -0.011 for age) tell us:\n",
    "  - Negative means \"as age goes up, survival chance goes down\"\n",
    "  - Positive would mean \"as age goes up, survival chance goes up\"\n",
    "  - The bigger the number, the stronger the effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hp39fZZCCgN"
   },
   "source": [
    "# Questions\n",
    "\n",
    "- We find a relationship between `Age` and `Survival`. Does this mean age *caused* survival differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9uOfj4vJGCk"
   },
   "source": [
    "# 2. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "OezOUbRXB_BJ",
    "outputId": "4335f9b1-e0a9-4f25-e22e-d8bda3400f5b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data\n",
    "df = train.dropna(subset=['Age'])\n",
    "X = df['Age'].values.reshape(-1, 1)  # Reshape to 2D array\n",
    "y = df['Survived']\n",
    "\n",
    "# Fit model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Create age range for smooth curve\n",
    "ages = np.linspace(0, 80, 100).reshape(-1, 1)\n",
    "probabilities = model.predict_proba(ages)[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Age'], y, alpha=0.5, label='Data')\n",
    "plt.plot(ages, probabilities, 'r-', label='Logistic Regression')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Titanic Survival by Age')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5N5G6hYJXp4"
   },
   "source": [
    "# Visualization ‚Äì Take II\n",
    "\n",
    "#### Our visualization does three important things:\n",
    "\n",
    "- Bins passengers into age groups (10 groups)\n",
    "- Calculates the actual survival rate for each age group (blue dots)\n",
    "- Shows the logistic regression prediction (red line)\n",
    "- The size of each dot shows how many passengers were in that age group\n",
    "\n",
    "# Plot Interpretation\n",
    "In our final plot:\n",
    "\n",
    "- Each blue dot represents an age group\n",
    "- The y-axis shows the proportion of people who survived in that age group\n",
    "- Bigger dots mean more passengers in that age group (so we can trust those points more)\n",
    "- The red line shows what our model predicts\n",
    "- If the red line slopes down, older passengers were less likely to survive\n",
    "- If it slopes up, older passengers were more likely to survive\n",
    "- The gap between the dots and the line shows where our model doesn't fit perfectly\n",
    "\n",
    "# Points\n",
    "- The gaps between dots and the line aren't \"errors\" - they show other factors we're not considering\n",
    "\n",
    "## Understanding Model Fit\n",
    "- Look at clusters of dots that the line misses:\n",
    "  - What else might explain survival here?\n",
    "- Look at age groups with very different survival rates:\n",
    "  - What might make young children have such high survival rates?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "yHvKiPVnB_PW",
    "outputId": "e311d8b7-3758-4d8f-80d4-532351b005ac"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data\n",
    "df_clean = train.dropna(subset=['Age']).copy()  # Create a clean copy\n",
    "\n",
    "# Create age bins and calculate mean survival rate for each bin\n",
    "df_clean.loc[:, 'AgeBin'] = pd.cut(df_clean['Age'], bins=10)  # Using .loc to avoid warning\n",
    "survival_by_age = df_clean.groupby('AgeBin', observed=True)['Survived'].agg(['mean', 'count']).reset_index()\n",
    "bin_centers = [(bin.left + bin.right)/2 for bin in survival_by_age['AgeBin']]\n",
    "\n",
    "# Fit logistic regression\n",
    "X = df_clean['Age'].values.reshape(-1, 1)\n",
    "y = df_clean['Survived']\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Create smooth curve\n",
    "ages = np.linspace(0, 80, 100).reshape(-1, 1)\n",
    "probabilities = model.predict_proba(ages)[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(bin_centers, survival_by_age['mean'],\n",
    "           s=survival_by_age['count']*2,  # Size proportional to count\n",
    "           alpha=0.6, label='Actual survival rate (by age group)')\n",
    "plt.plot(ages, probabilities, 'r-', label='Logistic regression')\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Titanic Survival Rate by Age')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print coefficients\n",
    "print(f\"\\nIntercept: {model.intercept_[0]:.3f}\")\n",
    "print(f\"Age coefficient: {model.coef_[0][0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bzWIVc7Bokt"
   },
   "source": [
    "# Interpretation\n",
    "\n",
    "Relate to probability: \"If we predict 0.7, that means we think there's a 70% chance of survival  \n",
    "\n",
    "# Questions\n",
    "\n",
    "- Looking at our age groups (blue dots), where do you think survival probability was highest? Lowest?\n",
    "\n",
    "- If our age coefficient is negative, what shape do you expect our red line to have?\n",
    "\n",
    "- Why are some dots bigger than others? What does that tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6stBT8WBB_V3"
   },
   "source": [
    "# Machine Learning\n",
    "Above is the classical 'statistics' version of logistic regression\n",
    "\n",
    "When we move to `machine learning`, we'll:\n",
    "  - Split our data into training and testing sets\n",
    "  - Use cross-validation\n",
    "  - Evaluate our model's performance more rigorously\n",
    "  - Evaluate the model on unseen data (the `test` set)\n",
    "  \n",
    "## Why Do Machine Learning? A Beginner's Guide\n",
    "\n",
    "### The Big Difference: Prediction vs. Understanding\n",
    "\n",
    "**Statistical Approach (What We Did First)**\n",
    "- Helps us understand relationships in our data\n",
    "- Tells us if age had a \"significant\" effect on survival\n",
    "- Great for testing hypotheses and understanding patterns\n",
    "- Like a scientist trying to understand why things happen\n",
    "\n",
    "**Machine Learning Approach (What We Just Did)**\n",
    "- Focuses on making good predictions\n",
    "- Tests how well we can predict survival for new passengers\n",
    "- Great for real-world applications\n",
    "- Like a fortune teller trying to predict what will happen next\n",
    "\n",
    "### A Real-World Example\n",
    "\n",
    "Imagine two different doctors:\n",
    "- Doctor A studies how age affects disease risk (statistical approach)\n",
    "- Doctor B tries to predict which patients will get sick (ML approach)\n",
    "\n",
    "Both are valuable, but they have different goals:\n",
    "- Doctor A helps us understand why age matters\n",
    "- Doctor B helps us identify high-risk patients early\n",
    "\n",
    "\n",
    "\n",
    "## Why Would We Want Machine Learning?\n",
    "\n",
    "1. **Testing Our Understanding**\n",
    "   - It's one thing to find patterns\n",
    "   - It's another to show these patterns work on new data\n",
    "   - ML makes us prove our model actually works\n",
    "\n",
    "2. **Real-World Applications**\n",
    "   - Sometimes we care more about making good predictions than understanding why\n",
    "   - Like Netflix predicting if you'll like a movie\n",
    "   - They care more about being right than understanding why you like movies\n",
    "\n",
    "3. **Future Use**\n",
    "   - Statistical approaches tell us about our current data\n",
    "   - ML approaches are built to handle new cases\n",
    "   - If the Titanic sailed today, could we predict who would survive?\n",
    "\n",
    "## When to Use Which Approach?\n",
    "\n",
    "**Use Statistical Approach When:**\n",
    "- You want to understand why things happen\n",
    "- You're testing specific theories\n",
    "- You need to convince others about relationships in your data\n",
    "- You're doing scientific research\n",
    "\n",
    "**Use Machine Learning When:**\n",
    "- You want to make predictions about new cases\n",
    "- You care more about accuracy than understanding\n",
    "- You're building a system that will be used in the real world\n",
    "- You want to see how well your model generalizes\n",
    "\n",
    "## The Bridge Between Them\n",
    "\n",
    "In our Titanic example:\n",
    "- Statistical approach told us age affected survival\n",
    "- Machine learning showed us how well we could use age to predict survival\n",
    "- Together, they give us a complete picture\n",
    "\n",
    "Think of it like weather:\n",
    "- Statistics helps us understand why it rains\n",
    "- Machine learning helps us predict if it will rain tomorrow\n",
    "- Both are valuable, just for different purposes!\n",
    "\n",
    "## Why Learn Both?\n",
    "\n",
    "Because in the real world:\n",
    "- Sometimes you need to understand why\n",
    "- Sometimes you need to predict what's next\n",
    "- Often you need both!\n",
    "\n",
    "Remember: Neither approach is \"better\" - they serve different purposes. Understanding both makes you a more complete data scientist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-k76QZxB_pP",
    "outputId": "d55e47fa-3579-43dc-c2dc-55b988515cdd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Prepare data\n",
    "df = train.dropna(subset=['Age'])\n",
    "X = df['Age'].values.reshape(-1, 1)  # reshape for sklearn\n",
    "y = df['Survived']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "model = LogisticRegression()\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "# Fit model on full training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Average CV score:\", cv_scores.mean())\n",
    "print(\"\\nModel coefficients:\")\n",
    "print('Intercept:', model.intercept_[0])\n",
    "print('Age coefficient:', model.coef_[0][0])\n",
    "print(\"\\nModel performance on test set:\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG6Y5c1rAWSc"
   },
   "source": [
    "Here's the raw markdown for a Jupyter notebook markdown cell:\n",
    "\n",
    "# Understanding Machine Learning Concepts\n",
    "\n",
    "## Train-Test Split\n",
    "\n",
    "In machine learning, we don't want to test our model on the same data we used to train it. That would be like giving students the answers while they take the test! Instead, we:\n",
    "- Split our data into a \"training set\" (like study materials) and a \"test set\" (like the final exam)\n",
    "- Use 80% for training (`test_size=0.2` means 20% for testing)\n",
    "- `random_state=42` just makes sure we get the same split every time we run the code\n",
    "\n",
    "In brief, think of this like 'teaching' and 'testing' students:\n",
    "- Training data is like study materials students use to learn\n",
    "- Test data is like the final exam\n",
    "- We want to know if students truly learned (can handle new questions) or just memorized\n",
    "\n",
    "When we use `train_test_split`:\n",
    "- 80% of our data goes to training (`test_size=0.2` means 20% for testing)\n",
    "- Model learns patterns from training data\n",
    "- We check how well these patterns work on test data\n",
    "\n",
    "## Cross-Validation\n",
    "\n",
    "Cross-validation helps us understand how well our model will work on new data:\n",
    "- It splits the training data into 5 parts (`cv=5`)\n",
    "- Trains the model 5 times, each time holding out a different part as a mini test set\n",
    "- Gives us 5 different accuracy scores\n",
    "- If these scores are similar, our model is stable\n",
    "- If they vary a lot, our model might be unreliable\n",
    "\n",
    "## Understanding the Results\n",
    "\n",
    "### Cross-validation Scores\n",
    "\n",
    "When you see this output:\n",
    "```\n",
    "Cross-validation scores: [0.6173913 , 0.65789474, 0.5877193, 0.60526316, 0.61403509]\n",
    "Average CV score: 0.6164607170099161\n",
    "```\n",
    "- Shows 5 different accuracy scores from cross-validation\n",
    "- The average tells us what accuracy to expect on new data\n",
    "- In this example, we might expect about 68% accuracy on new data\n",
    "\n",
    "### Model Coefficients\n",
    "\n",
    "When you see:\n",
    "```\n",
    "Intercept:0.171\n",
    "Age coefficient: -0.018\n",
    "```\n",
    "- Negative age coefficient means older passengers were less likely to survive\n",
    "- The actual predictions are probabilities between 0 and 1\n",
    "\n",
    "### Classification Report\n",
    "\n",
    "When you see a classification report, it shows:\n",
    "\n",
    "- **Precision**: Of the passengers we predicted would survive, what fraction actually survived?\n",
    "  - Example: Precision of 0.70 means when we predict survival, we're right 70% of the time\n",
    "\n",
    "- **Recall**: Of the passengers who actually survived, what fraction did we correctly identify?\n",
    "  - Example: Recall of 0.65 means we correctly identified 65% of actual survivors\n",
    "\n",
    "- **F1-score**: A balance between precision and recall (closer to 1 is better)\n",
    "\n",
    "- **Support**: How many examples we had in each category\n",
    "\n",
    "### Overall Accuracy\n",
    "\n",
    "When you see:\n",
    "```\n",
    "Accuracy: 0.601\n",
    "```\n",
    "- This means we correctly predicted survival 60% of the time\n",
    "- It's the simplest measure of our model's performance\n",
    "\n",
    "## Why This Version is Better\n",
    "\n",
    "1. We know how well our model works on new data (test set)\n",
    "2. Cross-validation tells us if our model's performance is stable\n",
    "3. We get detailed metrics about different types of errors\n",
    "4. We're following proper machine learning practices\n",
    "\n",
    "Remember: Our accuracy might seem low because we're only using Age. Real Titanic prediction models use many features (gender, class, fare, etc.) and achieve much higher accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbw9yE_ZL51E"
   },
   "source": [
    "# What's Next? Ways to Improve the Model\n",
    "\n",
    "1. **Add More Features**\n",
    "   - Age alone isn't enough to predict survival\n",
    "   - Add passenger class, gender, fare price, etc.\n",
    "   - This would likely improve accuracy significantly\n",
    "\n",
    "2. **Cross-Validation**\n",
    "   - Instead of one train-test split, use multiple splits\n",
    "   - Gives us more reliable performance estimates\n",
    "   - Helps ensure our model is stable\n",
    "\n",
    "3. **Feature Engineering**\n",
    "   - Create new features like \"traveling with family\"\n",
    "   - Group ages into categories\n",
    "   - Handle missing data better\n",
    "\n",
    "4. **Try Different Models**\n",
    "   - Random Forests\n",
    "   - Support Vector Machines\n",
    "   - Neural Networks\n",
    "\n",
    "5. **Hyperparameter Tuning**\n",
    "   - Adjust model settings for better performance\n",
    "   - Use techniques like grid search\n",
    "\n",
    "6. **Better Evaluation**\n",
    "   - Look at confusion matrices\n",
    "   - Consider different metrics (AUC-ROC)\n",
    "   - Analyze which types of passengers we predict best/worst\n",
    "\n",
    "Remember: This simple version helps understand the basics of machine learning, but real-world applications would use many of these improvements!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Four Different Models: Logistic Regression, Decision Tree, Random Forest, and XGBoost on *Three* Variables\n",
    "\n",
    "Below is an updated script that runs Logistic Regression, Decision Tree, Random Forest, and XGBoost using `GridSearchCV` to optimize hyperparameters. It then compares their performance.\n",
    "\n",
    "Key Enhancements\n",
    "- Uses `GridSearchCV` for hyperparameter tuning.\n",
    "- Adds `Decision Tree`, `Random Forest`, and `XGBoost` models.\n",
    "- Compares accuracy and provides a classification report.\n",
    "\n",
    "#### First, we will prepare the data by making transformations to the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Female'] = train['Sex'].map({'female': 1, 'male': 0}).fillna(0)  # Default to 0 if missing\n",
    "train['Age'] = train['Age'].fillna(train['Age'].mean())\n",
    "X = train[['Age', 'Female', 'Fare']]\n",
    "y = train['Survived'] # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative method of looking for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models and hyperparameters for GridSearch\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [3, 5, 10, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 10, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model':  XGBClassifier(eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [3, 5, 10],\n",
    "            'learning_rate': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    \n",
    "    \n",
    "# Perform GridSearchCV for each model\n",
    "results = {}\n",
    "for name, config in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    grid_search = GridSearchCV(config['model'], config['params'], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best model from GridSearch\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"Best Parameters:\", result['best_params'])\n",
    "    print(\"Accuracy:\", result['accuracy'])\n",
    "    #print(\"Classification Report:\\n\", result['classification_report'])\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the Results\n",
    "\n",
    "We see Great improvement by expanding `X`! Below is the **updated script** that:  \n",
    "- Uses `GridSearchCV` for **Logistic Regression, Decision Tree, Random Forest, and XGBoost**  \n",
    "- **Expands `X`** with `Age`, `Female`, and `Fare`  \n",
    "- **Prints a comparison table** showing accuracy and best hyperparameters  \n",
    "\n",
    "---\n",
    "\n",
    "### **What This Does:**\n",
    "- **Uses `GridSearchCV`** for **hyperparameter tuning** of all models.\n",
    "- **Expands `X`** to include:\n",
    "  - `Age`\n",
    "  - `Female` (binary encoding of `Sex`)\n",
    "  - `Fare`\n",
    "- **Adds `class_weight='balanced'`** to Random Forest to handle imbalanced data.\n",
    "- **Outputs a table** comparing accuracy and best hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### What are Hyperparameters?\n",
    "\n",
    "Hyperparameters are configuration settings for a machine learning model that are **not learned from the data** but rather set before training. They control the learning process and impact model performance. Examples include:  \n",
    "\n",
    "- **Regularization strength (`C`)** in Logistic Regression  \n",
    "- **Tree depth (`max_depth`)** in Decision Trees and Random Forests  \n",
    "- **Number of estimators (`n_estimators`)** in ensemble models like Random Forest and XGBoost  \n",
    "- **Learning rate (`learning_rate`)** in gradient boosting models  \n",
    "\n",
    "In your code, you define hyperparameters in the `params` dictionaries for each model and use **GridSearchCV** to find the best combination based on cross-validation.\n",
    "\n",
    "### Modified code ‚Äì output a table with key findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, config in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    grid_search = GridSearchCV(config['model'], config['params'], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best model from GridSearch\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Best Parameters': grid_search.best_params_,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the four models and `GridSearchCV`\n",
    "\n",
    "Here is a basic  of the four models is doing and how **GridSearchCV** helps us improve their performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Logistic Regression** (The Simple, Linear Approach)\n",
    "- Think of **Logistic Regression** as drawing a straight line (or plane) that **separates survivors from non-survivors** based on factors like age, gender, and fare.\n",
    "- It assigns each passenger a **probability of survival** (between 0 and 1). If the probability is above **50%**, the model predicts they survived.\n",
    "- It's a **simple and interpretable** model, making it a great starting point.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Decision Tree** (The Flowchart Approach)\n",
    "- Imagine a **series of \"Yes/No\" questions** that help predict survival.\n",
    "  - Example: \"Is the passenger female?\" ‚Üí If Yes, they are more likely to survive.\n",
    "  - \"Is their fare high?\" ‚Üí If Yes, they are more likely to survive.\n",
    "- The tree **splits the data into smaller and smaller groups** until it makes a prediction.\n",
    "- It‚Äôs easy to **visualize** but can sometimes **overfit** (memorize the data instead of generalizing well).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Random Forest** (The Teamwork Approach)\n",
    "- A **Random Forest** is just **a bunch of Decision Trees working together**.\n",
    "- Instead of relying on a single tree, it **creates many trees**, each seeing a different part of the data.\n",
    "- The model then **takes a vote** among the trees to decide the final prediction.\n",
    "- This **reduces overfitting** and makes it more **robust** than a single Decision Tree.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. XGBoost** (The Smart, Boosted Trees Approach)\n",
    "- **XGBoost** is an advanced tree-based model that **learns from mistakes**.\n",
    "- It starts with a weak Decision Tree, then **improves step by step** by focusing more on the passengers it got wrong.\n",
    "- This makes it **one of the most powerful models** for structured data like the Titanic dataset.\n",
    "- It‚Äôs often **the best choice for Kaggle competitions** because of its efficiency and accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### **What is GridSearchCV Doing?** (The Tuning Process)\n",
    "- Each model has **settings (called hyperparameters)** that control how it learns.\n",
    "- For example:\n",
    "  - In a **Decision Tree**, how deep should the tree go?\n",
    "  - In **Random Forest**, how many trees should we use?\n",
    "  - In **XGBoost**, how fast should it learn?\n",
    "- **GridSearchCV** is like a **chef testing different recipes** to find the perfect one.\n",
    "  - It **tries different combinations of settings** (e.g., testing different tree depths or learning rates).\n",
    "  - It **picks the best combination** based on performance (accuracy in this case).\n",
    "- This ensures **we're using the best possible version** of each model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Summary**\n",
    "- **Logistic Regression**: A **simple**, probability-based approach (like a straight-line decision).\n",
    "- **Decision Tree**: A **\"Yes/No\" question tree** that splits passengers into groups.\n",
    "- **Random Forest**: A **team of Decision Trees** voting together for better accuracy.\n",
    "- **XGBoost**: A **super-smart tree model** that fixes its mistakes step by step.\n",
    "- **GridSearchCV**: A **trial-and-error process** that finds the best settings for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the Model to the `test` Data\n",
    "\n",
    "First, let's re-run an abbreviated version of our logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['Age', 'Female', 'Fare']]\n",
    "y = train['Survived'] # Target variable\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit model on full training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel coefficients:\")\n",
    "print('Intercept:', model.intercept_[0])\n",
    "print('Age coefficient:', model.coef_[0][0])\n",
    "print('Female coefficient:', model.coef_[0][1])\n",
    "print('Fare coefficient:', model.coef_[0][2])\n",
    "print(\"\\nModel performance on test set:\")\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's read in our `test.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://raw.githubusercontent.com/gdsaxton/GDAN5400/refs/heads/main/Titanic/test.csv'\n",
    "test = pd.read_csv(test_url)\n",
    "print(len(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(test.columns) - set(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply same transformations to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Female'] = test['Sex'].map({'female': 1, 'male': 0}).fillna(0)  # Default to 0 if missing\n",
    "test['Female'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Age'] = test['Age'].fillna(train['Age'].median())  # Fill missing Age values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the 1 missing value on Fare\n",
    "test['Fare'] = test['Fare'].fillna(train['Fare'].median())  # Fill missing Fare values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test[['Age', 'Female', 'Fare']].isnull().sum())  # Check for missing values in model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the same predictor variables as in training\n",
    "X_test = test[['Age', 'Female', 'Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for Kaggle test set\n",
    "test_predictions = model.predict(X_test)\n",
    "print('# of predictions:', len(test_predictions))\n",
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBj_ipbBKV04"
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': test_predictions})\n",
    "print(len(output))\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\", '\\n')\n",
    "print(output['Survived'].value_counts(), '\\n')\n",
    "output[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Submit your Prediction to Kaggle\n",
    "\n",
    "Once you‚Äôre ready to make a submission and get on the leaderboard:\n",
    "\n",
    "1. Click on the **‚ÄúSubmit Predictions‚Äù** button\n",
    "\n",
    "![Submission Step 1](https://storage.googleapis.com/kaggle-media/welcome/screen1.png)\n",
    "\n",
    "<br><br>\n",
    "2. Upload a **CSV file** in the submission file format. You‚Äôre able to submit **10 submissions a day**.\n",
    "\n",
    "![Submission Step 2](https://storage.googleapis.com/kaggle-media/welcome/screen2.png)\n",
    "\n",
    "\n",
    "<br><br>\n",
    "### Submission File Format\n",
    "\n",
    "You should submit a **CSV file** with exactly **418 entries** plus a **header row**. Your submission will show an error if you have extra columns (beyond `PassengerId` and `Survived`) or rows.\n",
    "\n",
    "The file should have exactly **2 columns**:\n",
    "\n",
    "- **PassengerId** (sorted in any order)\n",
    "- **Survived** (contains your binary predictions: `1` for survived, `0` for deceased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PP_ue2K8OtcA"
   },
   "source": [
    "# Machine Learning Explainability \n",
    "https://www.kaggle.com/learn/machine-learning-explainability\n",
    "\n",
    "### 1. Permutation Importance\n",
    "https://www.kaggle.com/code/dansbecker/permutation-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(model, X_val, y_val, scoring='accuracy')\n",
    "print(perm_importance.importances_mean)\n",
    "\n",
    "# Convert results into a sorted DataFrame\n",
    "importances_df = (\n",
    "    pd.DataFrame({\n",
    "        \"Feature\": X_test.columns,\n",
    "        \"Importance\": perm_importance.importances_mean\n",
    "    })\n",
    "    .sort_values(by=\"Importance\", ascending=False)\n",
    ")\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", hue=\"Feature\", data=importances_df, palette=\"Blues_r\", legend=False)\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xlabel(\"Mean Importance Score\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.title(\"Feature Importance (Permutation Importance)\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Next? Ways to Improve the Model\n",
    "\n",
    "1. **Add More Features**\n",
    "   - Age alone isn't enough to predict survival\n",
    "   - Add passenger class, gender, fare price, etc.\n",
    "   - This would likely improve accuracy significantly\n",
    "\n",
    "2. **Cross-Validation**\n",
    "   - Instead of one train-test split, use multiple splits\n",
    "   - Gives us more reliable performance estimates\n",
    "   - Helps ensure our model is stable\n",
    "\n",
    "3. **Feature Engineering**\n",
    "   - Create new features like \"traveling with family\"\n",
    "   - Group ages into categories\n",
    "   - Handle missing data better\n",
    "\n",
    "4. **Try Different Models**\n",
    "   - Random Forests\n",
    "   - Support Vector Machines\n",
    "   - Neural Networks\n",
    "\n",
    "5. **Hyperparameter Tuning**\n",
    "   - Adjust model settings for better performance\n",
    "   - Use techniques like grid search\n",
    "\n",
    "6. **Better Evaluation**\n",
    "   - Look at confusion matrices\n",
    "   - Consider different metrics (AUC-ROC)\n",
    "   - Analyze which types of passengers we predict best/worst\n",
    "\n",
    "Remember: This simple version helps understand the basics of machine learning, but real-world applications would use many of these improvements!\n",
    "\n",
    "\n",
    "The **Kaggle Titanic dataset** is a classic introductory dataset for machine learning, containing structured data with both numerical and categorical features. Given its characteristics, different machine learning models can be tested to optimize prediction accuracy.\n",
    "\n",
    "# **Best Machine Learning Models for the Titanic Dataset**\n",
    "Since the task is **binary classification** (predicting survival: 0 = No, 1 = Yes), the following models are good candidates:\n",
    "\n",
    "#### **1. Logistic Regression (Baseline Model)**\n",
    "   - Simple, interpretable, and effective for binary classification.\n",
    "   - Handles categorical variables well when properly encoded.\n",
    "   - Works well with smaller datasets like Titanic.\n",
    "\n",
    "#### **2. Decision Trees**\n",
    "   - Captures non-linear relationships.\n",
    "   - Can handle missing values effectively.\n",
    "   - Prone to overfitting but useful as a benchmark.\n",
    "\n",
    "#### **3. Random Forest (Ensemble Model)**\n",
    "   - A collection of decision trees that improves accuracy and reduces overfitting.\n",
    "   - Performs well on structured data like Titanic.\n",
    "\n",
    "#### **4. Gradient Boosting Models (XGBoost, LightGBM, CatBoost)**\n",
    "   - More advanced than Random Forest, often yielding higher accuracy.\n",
    "   - XGBoost: Popular choice, excellent performance with hyperparameter tuning.\n",
    "   - LightGBM: Faster training speed, good for larger datasets.\n",
    "   - CatBoost: Handles categorical variables automatically.\n",
    "\n",
    "#### **5. Support Vector Machines (SVM)**\n",
    "   - Effective in high-dimensional space.\n",
    "   - Works well when the dataset is well-preprocessed and scaled.\n",
    "\n",
    "#### **6. k-Nearest Neighbors (k-NN)**\n",
    "   - Simple, non-parametric model that can perform well when properly tuned.\n",
    "   - Can be slow for large datasets.\n",
    "\n",
    "#### **7. Neural Networks (Deep Learning)**\n",
    "   - Usually overkill for small datasets like Titanic.\n",
    "   - Can be useful for feature extraction if expanded with additional data.\n",
    "\n",
    "### **Recommended Approach**\n",
    "1. **Preprocessing Steps**:\n",
    "   - Handle missing values (e.g., median/mean imputation for Age, mode for Embarked).\n",
    "   - Convert categorical variables (Sex, Embarked) into numerical format (one-hot encoding or label encoding).\n",
    "   - Normalize/scale numerical features.\n",
    "   - Feature engineering (e.g., extracting titles from names, creating family size).\n",
    "\n",
    "2. **Model Comparison**:\n",
    "   - Start with **Logistic Regression** as a baseline.\n",
    "   - Use **Random Forest or XGBoost** for improved performance.\n",
    "   - Tune hyperparameters using **GridSearchCV or RandomizedSearchCV**.\n",
    "   - Compare models using **cross-validation and AUC-ROC/F1-score**.\n",
    "\n",
    "3. **Stacking Models**:\n",
    "   - Combine models (e.g., blending Logistic Regression, Random Forest, and XGBoost) for improved performance.\n",
    "\n",
    "### **Best Model for Kaggle Competitions?**\n",
    "- **Gradient Boosting models (XGBoost, LightGBM, CatBoost) tend to outperform others on this dataset when tuned properly.**\n",
    "- **Feature engineering** (e.g., grouping passengers, extracting family relationships) plays a crucial role in top leaderboard performances.\n",
    "\n",
    "---\n",
    "\n",
    "### **How It Works**\n",
    "1. **Defines models**: Logistic Regression, Decision Tree, Random Forest, and XGBoost.\n",
    "2. **Uses GridSearchCV** to find optimal hyperparameters.\n",
    "3. **Trains and evaluates models** on the Titanic dataset.\n",
    "4. **Prints best hyperparameters, accuracy, and classification report** for each model.\n",
    "\n",
    "### **Expected Outcome**\n",
    "- You will see **best hyperparameters** for each model.\n",
    "- **Accuracy and classification report** for performance comparison.\n",
    "- This will help determine which model performs best for predicting survival.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 29507,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "035809f5dfaf449dad35f7577b30ea1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f40670003aa4b3d87bdae162f3dc6b5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3a5a15f344e54cefb9332bf5a0eff466",
      "value": "‚Äá47/47‚Äá[00:05&lt;00:00,‚Äá‚Äá5.36it/s,‚ÄáCompleted]"
     }
    },
    "0f40670003aa4b3d87bdae162f3dc6b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13e0ba926f2f4ead85a85d6d6467e911": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21483ffb63cc45388b23ec7e101b6b09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "228e72349ee74b54adcc6aedfb83d282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27caea6456a9430e97b54a5014bbc241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "291c2de1a99543fe8dc48394af560635": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30e2c17ffeeb4a538e3f81804b3f405c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3127f65572d04d3f851f5192800559b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_891d8203302c49ee901c8cfdec800480",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_590cd830f98a445b8b8ff661a6f1e520",
      "value": "Summarize‚Äádataset:‚Äá100%"
     }
    },
    "3a5a15f344e54cefb9332bf5a0eff466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "438248e5c9b74ce99a98ae5620b7d982": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45ef0bf3b41e4e4eaae21ee33d208ec0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e08a134cadd4478aac25ba96473a701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3127f65572d04d3f851f5192800559b1",
       "IPY_MODEL_a8c1ec8b30364d4eb68487acdc477b03",
       "IPY_MODEL_035809f5dfaf449dad35f7577b30ea1a"
      ],
      "layout": "IPY_MODEL_45ef0bf3b41e4e4eaae21ee33d208ec0"
     }
    },
    "516df8813ad44eb396d323da89b157ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_863516548a7644029f481ee2078fec6b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_27caea6456a9430e97b54a5014bbc241",
      "value": "‚Äá1/1‚Äá[00:00&lt;00:00,‚Äá30.25it/s]"
     }
    },
    "53576e5b381541599b222dd3daa81d92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dfea0518ee34f4eb55dfa8deb36c879",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5bca48df542b408cb2de7fdf1befaa1c",
      "value": 1
     }
    },
    "55c10e963e074b6dacae7336b10a83f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "590cd830f98a445b8b8ff661a6f1e520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bca48df542b408cb2de7fdf1befaa1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "605c1594e11b4791ac6046d2436075cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "630b7f6abc43402687310d5a1a8dee11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30e2c17ffeeb4a538e3f81804b3f405c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_228e72349ee74b54adcc6aedfb83d282",
      "value": 1
     }
    },
    "69946cb0bbfe4bd2a7e919a3dfdc0eb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aa99e9c5308426788d222b4df29cc44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f3c03ba852c4d1ab1027711601be623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75e2c39a711f411a9384ee9740a444f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69946cb0bbfe4bd2a7e919a3dfdc0eb9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a20842cf85514f8f928220e80d5d754f",
      "value": "Render‚ÄáHTML:‚Äá100%"
     }
    },
    "7dfea0518ee34f4eb55dfa8deb36c879": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81f09abf8e53446d9d5f905d17563a60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "863516548a7644029f481ee2078fec6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "891d8203302c49ee901c8cfdec800480": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95c88d8655634e4485ecd69c06cedaf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21483ffb63cc45388b23ec7e101b6b09",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_81f09abf8e53446d9d5f905d17563a60",
      "value": "‚Äá1/1‚Äá[00:01&lt;00:00,‚Äá‚Äá1.32s/it]"
     }
    },
    "9cc3f606fdda41428a2b565b70cffdb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a20842cf85514f8f928220e80d5d754f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2e677b111864535b01aeec28b396db0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75e2c39a711f411a9384ee9740a444f7",
       "IPY_MODEL_dc16db812ba046cfb4ebb5f07e0fec04",
       "IPY_MODEL_95c88d8655634e4485ecd69c06cedaf2"
      ],
      "layout": "IPY_MODEL_438248e5c9b74ce99a98ae5620b7d982"
     }
    },
    "a596ff23b7de4922b2eedfa5bf3ccc02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8c1ec8b30364d4eb68487acdc477b03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a596ff23b7de4922b2eedfa5bf3ccc02",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9cc3f606fdda41428a2b565b70cffdb1",
      "value": 5
     }
    },
    "b4d6553c1eea4375ae9d090eae8f423b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c660a50ffa754a97881ec7743f33b417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_605c1594e11b4791ac6046d2436075cb",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6aa99e9c5308426788d222b4df29cc44",
      "value": "‚Äá1/1‚Äá[00:07&lt;00:00,‚Äá‚Äá7.23s/it]"
     }
    },
    "d1e5a065932f4a518b5c2ef9003be9b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d29df846cca644fca527ca1571c7b89e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6d72e6822654cbeb7375a5ff7d2ed07",
       "IPY_MODEL_630b7f6abc43402687310d5a1a8dee11",
       "IPY_MODEL_516df8813ad44eb396d323da89b157ea"
      ],
      "layout": "IPY_MODEL_b4d6553c1eea4375ae9d090eae8f423b"
     }
    },
    "d6d72e6822654cbeb7375a5ff7d2ed07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13e0ba926f2f4ead85a85d6d6467e911",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_feccc05eb2184c1b8646ec28593ecb4a",
      "value": "Export‚Äáreport‚Äáto‚Äáfile:‚Äá100%"
     }
    },
    "dc16db812ba046cfb4ebb5f07e0fec04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1e5a065932f4a518b5c2ef9003be9b7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_291c2de1a99543fe8dc48394af560635",
      "value": 1
     }
    },
    "e4aaf95258d64d43947e12a43a24aa49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea93d9885edb4998833cf8d25bdfaa7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55c10e963e074b6dacae7336b10a83f1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e4aaf95258d64d43947e12a43a24aa49",
      "value": "Generate‚Äáreport‚Äástructure:‚Äá100%"
     }
    },
    "f692741bffb647d88547735a9b1b82f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea93d9885edb4998833cf8d25bdfaa7c",
       "IPY_MODEL_53576e5b381541599b222dd3daa81d92",
       "IPY_MODEL_c660a50ffa754a97881ec7743f33b417"
      ],
      "layout": "IPY_MODEL_6f3c03ba852c4d1ab1027711601be623"
     }
    },
    "feccc05eb2184c1b8646ec28593ecb4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
